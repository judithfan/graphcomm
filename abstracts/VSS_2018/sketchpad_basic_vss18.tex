\documentclass{article}
% General document formatting
\usepackage[margin=0.7in]{geometry}
\usepackage[parfill]{parskip}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{palatino}
\usepackage[none]{hyphenat}

% Related to math
\usepackage{amsmath,amssymb,amsfonts,amsthm}

\title{Modeling contextual flexibility in visual communication}
\author[a]{Judith E. Fan}
\author[a]{Robert X.D. Hawkins} 
\author[b]{Mike Wu}
\author[a,b]{Noah D. Goodman}

\affil[a]{Department of Psychology, Stanford University}
\affil[b]{Department of Computer Science, Stanford University}

\begin{document}
\maketitle

Visual modes of communication are ubiquitous in modern life --- from maps to data plots to political cartoons. Here we investigate drawing, the most basic form of visual communication. Communicative drawing poses a core challenge for theories of how vision and social cognition interact, requiring a detailed understanding of how sensory information and social context jointly determine what information is relevant to communicate. Participants (N=192) were paired in an online environment to play a drawing-based reference game. On each trial, both participants were shown the same four objects, but in different locations. The \textit{sketcher's} goal was to draw one of these objects --- the target --- so that the \textit{viewer} could pick it out from a set of distractor objects. There were two types of trials: \textit{close}, where objects belonged to the same category, and \textit{far}, where objects belonged to different categories. We found that people exploited information in common ground with their partner to efficiently communicate about the target: on far trials, sketchers achieved 99.7\% recognition accuracy while applying fewer strokes, using less ink, and spending less time (\textit{p}s$<$0.001) on their drawings than on close trials. We hypothesized that humans excel at this task by recruiting two core competencies: (1) \textbf{visual abstraction}, the capacity to perceive the correspondence between an object and a drawing of it; and (2) \textbf{social reasoning}, the ability to infer what information would help a viewer distinguish the target from distractors. We instantiated these competencies in a computational model that combines a multimodal convnet visual encoder with a Bayesian model of recursive social reasoning, and found that it fit the data well and outperformed lesioned variants of the model. Together, this work provides the first unified computational theory of how perception and social cognition support contextual flexibility in real-time visual communication.


\vspace{3mm}

\begin{description}  
\item Word Count: $\sim$ 300 of 300
\item Methodology/Approach: Behavior/Psychophysics
\item Primary Topic Descriptor: Perception and action: other
\item Secondary Topic Descriptor: XX
\item Funding sources: XXX
\item Presentation Preference: XXX
\item Suggested Reviewer 1: XXX
\item Suggested Reviewer 2: XXX
\item Suggested Reviewer 3: XXX
\end{description}


\end{document}