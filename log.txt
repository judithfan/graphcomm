
---
##project log for graphcomm 
####(to keep track of TODO's and archive meeting notes)
---

__July 7 2015 meeting notes__
_present = [jefan, ngoodman, rxdh, justinek]_

######

Sketches as signals -- what, if any, advantages might they have for studying reference & communication? 

Some possible responses:

1. can test against geometric ground truth (for concrete nouns) because we have precise control over image space (through object modeling & rendering), as well as ways good ways to measure visual features at various levels of abstraction (model output at each layer in HMO model)

2. relatedly, can look at emergence of systematicity or conventionalization in a continuous space (say, vs. among discrete lexicon). 

3. may be able to avoid some ceiling effects due to participants already having access to abstract concepts pre-packaged into words

What are some familiar graphical communication games that expose cool behaviors? Pictionary... and Celebrity. Celebrity involves fading out modalities available to communicate concept: first, full sentences, then words altogether, until you're stuck with just gestures. Yet people can do it! They seem to accomplish this both by learning directly what refers to what, as well as the space of alternatives. 

So, what if we directly manipulate the space of alternatives? Broad vs. narrow, spanning multiple categories or focusing on one. Question: how do task demands & scope of possibilities influence sketch output? How does the choice of worlds (space of literal meanings included in task) affect which splines end up being most informative, and thus (perhaps), prioritized in sketches?

Should people be pre-exposed to the objects, or should everyone start out ignorant? 

Would be really cool to explore systematicity. There seems to be some tentative forays into this (see Theisen, Oberlander, & Kirby, 2010), but with small sample size, coarse/qualitative measures. Already clearly an opportunity to study these on larger scale, with some possibly more powerful measures. 

Lest we get stuck working with only one task -- sketch referring to a single object -- could also play with defining novel/arbitrary categories, and see how people learn to convey those. 

Modeling using RSA & HMO convnet: Over what level of representation is an additional stroke informative? Naively, you might assume that what sketches are is simply edge extraction. If so, then presenting early layers of HMO with sketches should work to efficiently constrain reference to meanings (specified by RSA model).

Our guess is that natural strokes from human sketches are probably informative with respect to a more abstract feature space, such as that in Layer5 (resembling IT cortex), one that supports categorization, as opposed to at earliest layers (resembling V1). How can we formalize this? 

First computational experiment with RSA should deal with the one-shot version: you've got a 'speaker' (drawer?) and a 'listener' (observer?), and the drawer gets to generate a single spline to get the observer to guess what they're referring to. Because there's a nice generative model of the spline, it can use conditional inference to reason about which parameter settings $\theta$ would be most useful for the communication task. The model would look something like this:

```
var drawer = function(trueItem) {
  var splineParams = sample(splineParamERP);
  var sketch = drawSpline(splineParams);
  var convnetSketch = convnet(sketch);
  var convnetTrue   = convnet(trueItem);
  factor(similarity(convnetSketch, convnetTrue));
  return splineParams;
}
```

jef (Jul 10 2015): Gotcha. If I understand this somewhat correctly, the idea is to get a large sample of splines that people make to refer to an object, and then evaluate their informativeness by using a measure of feature similarity to the representation of the 3D model of the object in the CNN. A few clarification questions: (1) is it important to restrict analysis to only the first spline (vs. the complete sketch, or any other subset of splines from complete sketch)? (2) is similarity defined as the direct correspondence between the feature representation of the sketch and the feature representation of the image cue (e.g., dot product)?

rdh (Aug 6 2015): I've been thinking about this a little more. I think the answer to (1) is "no" and the answer to (2) is "it's an empirical question!" 

With respect to (1), you're not actually using a real person's sketch, you're just evaluating a randomly generated curve or set of curves and using that evaluation to guide a search for what curve or set of curves is most informative overall. So the simplest case (assuming something like MCMC for inference) would be sampling a single line (with four parameters: (x,y) locations of each end poing), mapping it to the feature representation space, evaluating its similarity to the 'true' object by some metric, and assigning it a score. This score then "upweights" parts of the distribution of true lines, and "downweights" other parts. So the next line you sample will be guided by the score of the previous one, and if you do that a million times, you'll end up with a distribution over all possible lines, peaked at the most informative ones! But a single line is kinda bad overall (i.e. even the *most* informative one probably isn't *that* informative). So then you could switch to sampling a spline, or a set of splines, and giving them scores in the same way. So we can analyze whatever generative process we think is most interesting.

With respect to (2), I have no clue what the right similarity function should be! I was going to use the dot product between the feature representations as the first pass, but let me know if you have a better idea. In fact, it might be an interesting mini-study to test a bunch of different similarity functions to see which ones work the best...

After running inference on this for a lot of iterations, you'd have some distribution of splines that you think are similarly to the true item in CNN space. Note that this does not require reasoning about the other agent at all: it's just trying to be informative with respect to the literal meaning of the drawing.

Let's explore this with some existing data sets, maybe collect some sketch data to accompany tangram text data, and mock up simplest RSA model. 

__TODO's__

(0) Take the sketches from existing 'sketchloop' experiment and extract strokes (already done), apply simplest literal model. 

(1) In existing tangram experiment, try version with sketches as utterances (to be able to compare against verbal data).

(2) Mock up simplest version of RSA model to express prior distribution over strokes/splines and how it updates when 0th order recursive reasoning deployed (i.e., literal meaning). Any use for existing sketch set from previous learning study?

(3) Meet again at CogSci (+ Dan). 






