{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT: preprocessed group data CSV from mongo (see pilot2_analysis_sketchpad_basic)\n",
    "## OUTPUT: full set of bdaInput files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__list of bdaInpput files__: \n",
    "* sketchData CSV (generated inside generate_bdaInput_csv)\n",
    "* test_examples TXT/JSON/CSV (generated inside generate_bdaInput_csv)\n",
    "* costs JSON\n",
    "* condition-lookup JSON\n",
    "* similarity JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load in sketch data and filter to generate sketchData CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "iterationName = 'pilot2'\n",
    "exp_path = './'\n",
    "analysis_dir = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','data',exp_path))\n",
    "exp_dir = './'\n",
    "sketch_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','analysis',exp_path,'sketches','pilot2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2682, 24)\n",
      "2682 records in merged dataframe\n",
      "194 incorrect trials\n",
      "132 invalid trials\n",
      " \n",
      "3072 trials with NO GARBAGE filtered out\n",
      "2878 trials with incorrects filtered out\n",
      "2940 trials with invalids filtered out\n",
      "2682 trials with ALL GARBAGE filtered out\n"
     ]
    }
   ],
   "source": [
    "D = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data.csv'))\n",
    "DUNFIL = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data_unfiltered.csv'))\n",
    "\n",
    "# filter out incorrect and invalid trials as well\n",
    "incorrects = pd.read_csv('./incorrect_trial_paths_pilot2.txt',header=None)[0].values\n",
    "invalids = pd.read_csv('./invalid_trial_paths_pilot2.txt',header=None)[0].values\n",
    "\n",
    "def add_fnames(D):\n",
    "    fname = []\n",
    "    for i,_d in D.iterrows():\n",
    "        fname.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '_' + _d['target'] +'.png')    \n",
    "    D = D.assign(fname=pd.Series(fname).values)  \n",
    "\n",
    "    fname_no_target = []\n",
    "    for i,_d in D.iterrows():\n",
    "        fname_no_target.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) +'.png')    \n",
    "    D = D.assign(fname_no_target=pd.Series(fname_no_target).values) \n",
    "    return D\n",
    "\n",
    "def filter_out_incorrect(D, incorrects):\n",
    "    D = D[~D['fname'].isin(incorrects)]\n",
    "    return D\n",
    "\n",
    "def filter_out_invalids(D, invalids):\n",
    "    D = D[~D['fname_no_target'].isin(invalids)] \n",
    "    return D\n",
    "    \n",
    "## add some filename columns\n",
    "D = add_fnames(D)\n",
    "DUNFIL = add_fnames(DUNFIL) ## version of dataframe with ALL trials, garbage games, incorrect trials, invalid trials\n",
    "\n",
    "DNOINC = filter_out_incorrect(DUNFIL, incorrects) ## save version of D containing with incorrect trials filtered out only\n",
    "DNOINV = filter_out_invalids(DUNFIL, invalids) ## save version of D containing with invalid trials filtered out only\n",
    "D = filter_out_invalids(filter_out_incorrect(D, incorrects), invalids) ## both kinds of garbage filtered out\n",
    "\n",
    "print np.shape(D)\n",
    "print str(np.shape(D)[0]) + ' records in merged dataframe'\n",
    "\n",
    "print '{} incorrect trials'.format(len(incorrects))\n",
    "print '{} invalid trials'.format(len(invalids))\n",
    "print ' '\n",
    "print '{} trials with NO GARBAGE filtered out'.format(DUNFIL.shape[0])\n",
    "print '{} trials with incorrects filtered out'.format(DNOINC.shape[0])\n",
    "print '{} trials with invalids filtered out'.format(DNOINV.shape[0])\n",
    "print '{} trials with ALL GARBAGE filtered out'.format(D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now assign sketch_label and class_label for the other versions of D\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "def add_extra_label_columns(D):\n",
    "    sketch_label = [(i[-12:] + '_' + str(j)) for i,j in zip(D['gameID'].values,D['trialNum'].values)]\n",
    "    D = D.assign(sketch_label=pd.Series(sketch_label).values)\n",
    "\n",
    "    # add class label\n",
    "    category = []\n",
    "    classes = ['bird','car','chair','dog']\n",
    "    for i,d in D.iterrows():\n",
    "        category.append(h.objcat[d['target']])\n",
    "    D = D.assign(category=pd.Series(category).values)\n",
    "    return D\n",
    "\n",
    "D = add_extra_label_columns(D)\n",
    "DUNFIL = add_extra_label_columns(DUNFIL)\n",
    "DNOINC = add_extra_label_columns(DNOINC)\n",
    "DNOINV = add_extra_label_columns(DNOINV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bdaInput_csv(D,filtration_level,train_test_split=True,\n",
    "                          adaptor_type='sketch_avg_full25k',\n",
    "                          split_type='splitbyobject'):\n",
    "\n",
    "    ### filter out training examples \n",
    "    test_examples = pd.read_json('pilot2_{}_test_examples.json'.format(adaptor_type),orient='records')\n",
    "    test_examples = list(test_examples[0].values)\n",
    "    test_examples = [i.split('.')[0] + '.png' for i in test_examples]    \n",
    "\n",
    "    if train_test_split==True:\n",
    "        keep_examples = test_examples \n",
    "    else:\n",
    "        keep_examples = D['fname_no_target'].values ## keep all datapoints\n",
    "\n",
    "    D0 = D[D['fname_no_target'].isin(keep_examples)]\n",
    "\n",
    "    ## generate lists to compose new bdaInput CSV\n",
    "    _sketchLabel = []\n",
    "    _Condition = []\n",
    "    _Target = []\n",
    "    _Distractor1 = []\n",
    "    _Distractor2 = []\n",
    "    _Distractor3 = []\n",
    "    _coarseGrainedSketchInfo = [] # condition_objectName ... e.g., further_knob\n",
    "    for i, _d in D0.iterrows():\n",
    "        _sketchLabel.append(_d['sketch_label'])\n",
    "        _Condition.append(_d['condition']) \n",
    "        _Target.append(_d['target'])\n",
    "        distractor1 = _d['Distractor1']\n",
    "        distractor2 = _d['Distractor2']\n",
    "        distractor3 = _d['Distractor3']      \n",
    "        \n",
    "        d_list = sorted([distractor1, distractor2, distractor3])\n",
    "        _Distractor1.append(d_list[0])\n",
    "        _Distractor2.append(d_list[1])    \n",
    "        _Distractor3.append(d_list[2])  \n",
    "        _coarseGrainedSketchInfo.append('{}_{}'.format(_d['condition'],_d['target'])) \n",
    "\n",
    "    D2 = pd.DataFrame([_Condition,_sketchLabel,_Target,_Distractor1,_Distractor2,_Distractor3,_coarseGrainedSketchInfo])\n",
    "    D2 = D2.transpose()\n",
    "    D2.columns = ['condition','sketchLabel','Target','Distractor1','Distractor2','Distractor3','coarseGrainedSketchInfo']\n",
    "    print '{} datapoints x {} columns'.format(D2.shape[0],D2.shape[1])\n",
    "    \n",
    "    if train_test_split==True:\n",
    "        print 'saving CSV with only test data'\n",
    "        if len(filtration_level)==0:\n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2.csv'.format(split_type,adaptor_type))\n",
    "        else:  \n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2_{}.csv'.format(split_type,adaptor_type,filtration_level))\n",
    "    else: ## run bda on ALL datapoints (not just test split)\n",
    "        print 'saving CSV including all datapoints'\n",
    "        if len(filtration_level)==0:\n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_alldata_{}_pilot2.csv'.format(adaptor_type))\n",
    "        else:  \n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_alldata_{}_pilot2_{}.csv'.format(adaptor_type,filtration_level))        \n",
    "    print 'Saved out bdaInput CSV ... {}'.format(filtration_level) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now actually generate and save out the bdaInputCSV, both the split and alldata versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544 datapoints x 7 columns\n",
      "saving CSV with only test data\n",
      "Saved out bdaInput CSV ... \n",
      "573 datapoints x 7 columns\n",
      "saving CSV with only test data\n",
      "Saved out bdaInput CSV ... no_incorrect\n",
      "574 datapoints x 7 columns\n",
      "saving CSV with only test data\n",
      "Saved out bdaInput CSV ... no_invalid\n",
      "608 datapoints x 7 columns\n",
      "saving CSV with only test data\n",
      "Saved out bdaInput CSV ... unfiltered\n",
      "2682 datapoints x 7 columns\n",
      "saving CSV including all datapoints\n",
      "Saved out bdaInput CSV ... \n",
      "2878 datapoints x 7 columns\n",
      "saving CSV including all datapoints\n",
      "Saved out bdaInput CSV ... no_incorrect\n",
      "2940 datapoints x 7 columns\n",
      "saving CSV including all datapoints\n",
      "Saved out bdaInput CSV ... no_invalid\n",
      "3072 datapoints x 7 columns\n",
      "saving CSV including all datapoints\n",
      "Saved out bdaInput CSV ... unfiltered\n"
     ]
    }
   ],
   "source": [
    "## params\n",
    "adaptor_type = 'sketch_avg_full25k'\n",
    "split_type = 'splitbyobject'\n",
    "\n",
    "# first split versions\n",
    "generate_bdaInput_csv(D,'',adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINC,'no_incorrect',adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINV,'no_invalid',adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DUNFIL,'unfiltered',adaptor_type = adaptor_type,split_type = split_type)\n",
    "\n",
    "# now alldata versions\n",
    "generate_bdaInput_csv(D,'',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINC,'no_incorrect',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINV,'no_invalid',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DUNFIL,'unfiltered',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove cost outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load data in again and filter out cost outliers\n",
    "\n",
    "def remove_outliers(X,column):\n",
    "    mu = np.mean(X[column].values)\n",
    "    sd = np.std(X[column].values)\n",
    "    thresh = mu + 5*sd        \n",
    "    X = X.drop(X[X[column] > thresh].index)\n",
    "    return X\n",
    " \n",
    "## make copy of D that has cost outliers removed    \n",
    "D2 = remove_outliers(D,'drawDuration')    \n",
    "D2 = remove_outliers(D2,'mean_intensity')\n",
    "D2 = remove_outliers(D2,'numStrokes')\n",
    "\n",
    "# print D2.shape\n",
    "\n",
    "splits = ['splitbyobject','alldata']\n",
    "for split in splits:\n",
    "    ### subset drawing data csv by sketches that are accounted for here (i.e., that were not cost outliers)\n",
    "    B = pd.read_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2.csv'.format(split_type,adaptor_type))    \n",
    "#     print B.shape\n",
    "\n",
    "    remaining_sketches = list(np.unique(D2['sketch_label'].values))\n",
    "    _B = B[B['sketchLabel'].isin(remaining_sketches)]\n",
    "#     print _B.shape\n",
    "    _B.to_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2_costOutliersRemoved.csv'.format(split,adaptor_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make condition-lookup json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## generate condition-lookup.json to be able to pair sketches with condition\n",
    "cond_json = {}\n",
    "sketchID_list = np.unique(D['sketch_label'].values)\n",
    "for i,d in enumerate(sketchID_list):\n",
    "    cond = D[D['sketch_label']==d]['condition'].values[0]\n",
    "    obj = D[D['sketch_label']==d]['target'].values[0]\n",
    "    cond_json[d] = '{}_{}'.format(cond,obj)\n",
    "    \n",
    "## output json in the same format as the other cost json\n",
    "output_path = '../models/bdaInput/condition-lookup.json'\n",
    "with open(output_path, 'wb') as fp:\n",
    "    json.dump(cond_json, fp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate cost dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,k=1,x0=0.5):\n",
    "    return 1 / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "def add_rescaled_metric(X,metric,transform='maxnorm',k=5):\n",
    "    '''\n",
    "    input: X is a data frame, metric is the name of one of the (cost) metrics that you want to scale between 0 and 1\n",
    "            transform options include:\n",
    "                :'maxnorm', which means dividing each value by maximum in list\n",
    "                :'minmaxnorm', look at it\n",
    "                :'sigmoid', which means passing each value through logistic function with mean\n",
    "    output: X with additional column that has the rescaled metric\n",
    "    '''\n",
    "    if metric=='drawDuration': ## if handling drawDuration, log first -- no wait, maybe not \n",
    "        vals = X[metric].values\n",
    "    else:\n",
    "        vals = X[metric].values\n",
    "    X['vals'] = vals\n",
    "    if transform=='maxnorm':\n",
    "        top_val = np.max(vals)\n",
    "        rescaled_val = []\n",
    "        for i,d in X.iterrows():\n",
    "            rescaled_val.append(d['vals']/top_val)\n",
    "    elif transform=='minmaxnorm':\n",
    "        bottom_val = np.min(vals)\n",
    "        top_val = np.max(vals)\n",
    "        rescaled_val = []\n",
    "        for i,d in X.iterrows():\n",
    "            rescaled_val.append((d['vals']-bottom_val)/(top_val-bottom_val))        \n",
    "    elif transform=='sigmoid':\n",
    "        median_val = np.median(vals)\n",
    "        rescaled_val = []\n",
    "        for i,d in X.iterrows():\n",
    "            rescaled_val.append(sigmoid(d['vals'],k=k,x0=median_val))\n",
    "    X['rescaled_{}'.format(metric)] = rescaled_val          \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## actually add rescaled metric\n",
    "D2 = add_rescaled_metric(D2,'numStrokes',transform='minmaxnorm')\n",
    "D2 = add_rescaled_metric(D2,'mean_intensity',transform='minmaxnorm')\n",
    "D2 = add_rescaled_metric(D2,'drawDuration',transform='minmaxnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653\n",
      "drawDuration\n",
      "mean_intensity\n",
      "numStrokes\n"
     ]
    }
   ],
   "source": [
    "## generate cost dictionaries to try out with pragmatics model\n",
    "print len(np.unique(D2['sketch_label'].values))\n",
    "sketchID_list = np.unique(D2['sketch_label'].values)\n",
    "metrics = ['drawDuration','mean_intensity','numStrokes']\n",
    "\n",
    "for metric in metrics:    \n",
    "    print metric\n",
    "    cost_json = {}\n",
    "    for i,d in enumerate(sketchID_list):\n",
    "        assert len(np.unique(D2[D2['sketch_label']==d]['rescaled_{}'.format(metric)].values))==1\n",
    "        cost_json[d] = D2[D2['sketch_label']==d]['rescaled_{}'.format(metric)].values[0]    \n",
    "\n",
    "    ## output json in the same format as the other cost json\n",
    "    output_path = '../models/refModule/json/costs-fixedPose96-{}.json'.format(metric)\n",
    "    with open(output_path, 'wb') as fp:\n",
    "        json.dump(cost_json, fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model predictions (bdaOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define set of models to compare\n",
    "# model_zoo = ['fc6_combined_cost','fc6_combined_nocost','fc6_S0_cost','fc6_S0_nocost']\n",
    "model_zoo = ['sketch-avg-full25k_combined_cost', 'sketch-unroll-full25k_S0_cost']\n",
    "this_model = model_zoo[0]\n",
    "\n",
    "## define paths to model predictions\n",
    "path_to_evaluate = '../models/evaluateOutput'\n",
    "pred_path = os.path.join(path_to_evaluate,this_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in model param posterior (bdaOutput/**splitbyobjectParams.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get file with params from this model\n",
    "this_params = os.path.join('../models/bdaOutput',this_model+'_splitbyobjectParams.csv')\n",
    "params = pd.read_csv(this_params)\n",
    "assert np.round(np.sum(np.exp(params.posteriorProb.values)),12)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '../models/evaluateOutput/sketch-avg-full25k_combined_cost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1bc03b43e532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## get list of all predictives (accepted MCMC samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'Predictives.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '../models/evaluateOutput/sketch-avg-full25k_combined_cost'"
     ]
    }
   ],
   "source": [
    "## get list of all predictives (accepted MCMC samples)\n",
    "pred_files = [i for i in os.listdir(pred_path) if i[-15:] =='Predictives.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
