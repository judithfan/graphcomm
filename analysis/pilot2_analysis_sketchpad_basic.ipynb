{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "import analysis_helpers as h\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "iterationName = 'pilot2'\n",
    "exp_path = './'\n",
    "analysis_dir = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','data',exp_path))\n",
    "exp_dir = './'\n",
    "sketch_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','analysis',exp_path,'sketches','pilot2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['sketchpad_basic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = coll.find({ '$and': [{'iterationName':'pilot2'}, {'eventType': 'stroke'}]}).sort('time')\n",
    "C = coll.find({ '$and': [{'iterationName':'pilot2'}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "print str(S.count()) + ' stroke records in the database.'\n",
    "print str(C.count()) + ' clickedObj records in the database.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print unique gameid's\n",
    "unique_gameids = coll.find({ '$and': [{'iterationName':'pilot2'}, {'eventType': 'clickedObj'}]}).sort('time').distinct('gameid')\n",
    "# print map(str,unique_gameids)\n",
    "\n",
    "# filter out  records that match researcher ID's\n",
    "jefan = ['A1MMCS8S8CTWKU','A1MMCS8S8CTWKV','A1MMCS8S8CTWKS']\n",
    "hawkrobe = ['A1BOIDKD33QSDK']\n",
    "researchers = jefan + hawkrobe\n",
    "workers = [i for i in coll.find({'iterationName':'pilot2'}).distinct('workerId') if i not in researchers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_gameids = []\n",
    "for i,g in enumerate(unique_gameids):\n",
    "    W = coll.find({ '$and': [{'gameid': g}]}).distinct('workerId')\n",
    "    for w in W:\n",
    "        if w in workers:\n",
    "            X = coll.find({ '$and': [{'workerId': w}, {'gameid': g}]}).distinct('trialNum') ## # of trials completed\n",
    "            eventType = coll.find({ '$and': [{'workerId': w}]}).distinct('eventType')\n",
    "            print i, w[:4], len(X), str(eventType[0])\n",
    "            if (str(eventType[0])=='clickedObj') & (len(X)==32):\n",
    "                valid_gameids.append(g)\n",
    "print '   ===========   '\n",
    "\n",
    "## filter if the pair cheated by writing words or using other symbols\n",
    "cheaty = ['8155-e46a25a3-9259-4b76-80e9-5bd79b6bdd97','6224-ab96ed5c-2a98-477c-aae2-7398b9e5b237',\\\n",
    "         '5595-a00b8109-1910-43c4-9f14-00eb4945ac70','1697-7ab5b295-fae8-4f62-8cbd-72aa0e23b10e']\n",
    "motor = ['2829-820b338d-5720-4964-bd22-8ba38329569d'] # this person made multiples in several of their sketches, and appeared to suffer from strong tremors\n",
    "unfiltered_gameids = valid_gameids\n",
    "valid_gameids = [i for i in valid_gameids if i not in cheaty]\n",
    "valid_gameids = [i for i in valid_gameids if i not in motor]\n",
    "\n",
    "print str(len(valid_gameids)) + ' valid gameIDs (# complete games).'\n",
    "\n",
    "df = pd.DataFrame([valid_gameids])\n",
    "df = df.transpose()\n",
    "df.columns=['valid_gameids']\n",
    "df.to_csv('valid_gameids_pilot2.csv')\n",
    "\n",
    "df = pd.DataFrame([unfiltered_gameids])\n",
    "df = df.transpose()\n",
    "df.columns=['unfiltered_gameids']\n",
    "df.to_csv('unfiltered_gameids_pilot2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TrialNum = []\n",
    "GameID = []\n",
    "Condition = []\n",
    "Target = []\n",
    "Distractor1 = []\n",
    "Distractor2 = []\n",
    "Distractor3 = []\n",
    "Outcome = []\n",
    "Response = []\n",
    "numStrokes = []\n",
    "drawDuration = [] # in seconds\n",
    "viewerRT = []\n",
    "svgStringLength = [] # sum of svg string for whole sketch\n",
    "svgStringLengthPerStroke = [] # svg string length per stroke\n",
    "numCurvesPerSketch = [] # number of curve segments per sketch\n",
    "numCurvesPerStroke = [] # mean number of curve segments per stroke\n",
    "svgStringStd = [] # std of svg string length across strokes for this sketch\n",
    "Outcome = []\n",
    "Pose = []\n",
    "Svg = []\n",
    "\n",
    "these_gameids = valid_gameids\n",
    "\n",
    "for g in these_gameids:\n",
    "    print 'Analyzing game: ', g\n",
    "\n",
    "    X = coll.find({ '$and': [{'gameid': g}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "    Y = coll.find({ '$and': [{'gameid': g}, {'eventType': 'stroke'}]}).sort('time')\n",
    "\n",
    "    for t in X:\n",
    "        targetname = t['intendedName']\n",
    "        distractors = [t['object2Name'],t['object3Name'],t['object4Name']]\n",
    "        full_list = [t['intendedName'],t['object2Name'],t['object3Name'],t['object4Name']] \n",
    "        y = coll.find({ '$and': [{'gameid': g}, {'eventType': 'stroke'}, {'trialNum': t['trialNum']}]}).sort('time')\n",
    "        ns = y.count()\n",
    "        numStrokes.append(ns)\n",
    "        drawDuration.append((y.__getitem__(ns-1)['time'] - y.__getitem__(0)['time'])/1000) # in seconds  \n",
    "        y = coll.find({ '$and': [{'gameid': g}, {'eventType': 'stroke'}, {'trialNum': t['trialNum']}]}).sort('time')        \n",
    "        z = coll.find({ '$and': [{'gameid': g}, {'eventType': 'clickedObj'}, {'trialNum': t['trialNum']}]}).sort('time')\n",
    "        viewerRT.append((z.__getitem__(0)['time'] - y.__getitem__(ns-1)['time'])/1000)\n",
    "        ls = [len(_y['svgData']) for _y in y]\n",
    "        svgStringLength.append(reduce(lambda x, y: x + y, ls))\n",
    "        y = coll.find({ '$and': [{'gameid': g}, {'eventType': 'stroke'}, {'trialNum': t['trialNum']}]}).sort('time')\n",
    "        num_curves = [len([m.start() for m in re.finditer('c', _y['svgData'])]) for _y in y]\n",
    "        y = coll.find({ '$and': [{'gameid': g}, {'eventType': 'stroke'}, {'trialNum': t['trialNum']}]}).sort('time')        \n",
    "        _svg = []\n",
    "        for _y in y:\n",
    "            _svg.append(_y['svgData'])\n",
    "        Svg.append(_svg)\n",
    "        numCurvesPerSketch.append(reduce(lambda x, y: x + y, num_curves))\n",
    "        numCurvesPerStroke.append(reduce(lambda x, y: x + y, num_curves)/ns)\n",
    "        svgStringLengthPerStroke.append(reduce(lambda x, y: x + y, ls)/ns)\n",
    "        svgStringStd.append(np.std(ls))\n",
    "        ### aggregate game metadata\n",
    "        TrialNum.append(t['trialNum'])\n",
    "        GameID.append(t['gameid'])        \n",
    "        Target.append(targetname)\n",
    "        Condition.append(t['condition'])\n",
    "        Response.append(t['clickedName'])\n",
    "        Outcome.append(t['correct'])\n",
    "        Distractor1.append(distractors[0])\n",
    "        Distractor2.append(distractors[1])\n",
    "        Distractor3.append(distractors[2])\n",
    "        Pose.append(t['pose'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## compose pandas dataframe from lists\n",
    "iteration = ['pilot2']*len(GameID)\n",
    "\n",
    "_D = pd.DataFrame([GameID,TrialNum,Condition, Target, drawDuration, Outcome, Response, numStrokes, \\\n",
    "                  svgStringLength, svgStringLengthPerStroke, svgStringStd, Distractor1, Distractor2, \\\n",
    "                   Distractor3, Pose, iteration, Svg, viewerRT]) \\\n",
    "\n",
    "D =_D.transpose()\n",
    "D.columns = ['gameID','trialNum','condition', 'target', 'drawDuration','outcome', 'response', \\\n",
    "             'numStrokes', 'svgStringLength', 'svgStringLengthPerStroke', 'svgStringStd', \\\n",
    "            'Distractor1', 'Distractor2', 'Distractor3', 'pose', 'iteration', 'svg','viewerRT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add png to D dataframe\n",
    "png = []\n",
    "for g in these_gameids:\n",
    "    X = coll.find({ '$and': [{'gameid': g}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "    Y = coll.find({ '$and': [{'gameid': g}, {'eventType': 'stroke'}]}).sort('time')\n",
    "    # print out sketches from all trials from this game\n",
    "    for t in X: \n",
    "        png.append(t['pngString'])\n",
    "D = D.assign(png=pd.Series(png).values)\n",
    "\n",
    "iteration = ['pilot2']*len(D['gameID'].values)\n",
    "D = D.assign(iteration=pd.Series(iteration).values)\n",
    "\n",
    "## add another cost-related dependent measure: mean pixel intensity (amount of ink spilled) -- to handle\n",
    "## some weird glitches in the num stroke count\n",
    "mean_intensity = []\n",
    "imsize = 100\n",
    "numpix = imsize**2\n",
    "thresh = 250\n",
    "\n",
    "for i,_d in D.iterrows():\n",
    "    imgData = _d['png']\n",
    "    filestr = base64.b64decode(imgData)\n",
    "    fname = os.path.join('sketch.png')\n",
    "    with open(fname, \"wb\") as fh:\n",
    "        fh.write(imgData.decode('base64'))\n",
    "    im = Image.open(fname).resize((imsize,imsize))\n",
    "    _im = np.array(im)\n",
    "    mean_intensity.append(len(np.where(_im[:,:,3].flatten()>thresh)[0])/numpix)\n",
    "    \n",
    "# add mean_intensity to the main D dataframe \n",
    "### btw: mean_intensity and numStrokes is about 0.43 spearman correlated.\n",
    "D = D.assign(mean_intensity=pd.Series(mean_intensity).values)\n",
    "print stats.spearmanr(D['mean_intensity'].values,D['numStrokes'].values)\n",
    "\n",
    "category = [h.objcat[t] for t in D.target.values]\n",
    "D = D.assign(category=pd.Series(category).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save D out as group_data.csv \n",
    "if len(np.unique(D.gameID.values))==len(valid_gameids):\n",
    "    D.to_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data.csv'))\n",
    "    print 'Saving out valid games csv'\n",
    "elif len(np.unique(D.gameID.values))==len(unfiltered_gameids):\n",
    "    D.to_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data_unfiltered.csv'))\n",
    "    print 'Saving out unfiltered games csv'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read group data csv in as D\n",
    "D = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get summary statistics\n",
    "all_games = np.unique(D['gameID'])\n",
    "further_strokes = []\n",
    "closer_strokes = []\n",
    "further_svgLength = []\n",
    "closer_svgLength = []\n",
    "further_svgStd = []\n",
    "closer_svgStd = []\n",
    "further_svgLengthPS = []\n",
    "closer_svgLengthPS = []\n",
    "further_drawDuration = []\n",
    "closer_drawDuration = []\n",
    "further_accuracy = []\n",
    "closer_accuracy = []\n",
    "closer_meanintensity = []\n",
    "further_meanintensity = []\n",
    "closer_viewerRT = []\n",
    "further_viewerRT = []\n",
    "\n",
    "for game in all_games:    \n",
    "    further_strokes.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['numStrokes'].mean())\n",
    "    closer_strokes.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['numStrokes'].mean())\n",
    "    further_svgLength.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['svgStringLength'].mean())\n",
    "    closer_svgLength.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['svgStringLength'].mean())\n",
    "    further_svgStd.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['svgStringStd'].mean())\n",
    "    closer_svgStd.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['svgStringStd'].mean())    \n",
    "    further_svgLengthPS.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['svgStringLengthPerStroke'].mean())\n",
    "    closer_svgLengthPS.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['svgStringLengthPerStroke'].mean())\n",
    "    further_drawDuration.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['drawDuration'].mean())\n",
    "    closer_drawDuration.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['drawDuration'].mean())\n",
    "    further_accuracy.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['outcome'].mean())\n",
    "    closer_accuracy.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['outcome'].mean())\n",
    "    closer_meanintensity.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['mean_intensity'].mean())    \n",
    "    further_meanintensity.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['mean_intensity'].mean())        \n",
    "    closer_viewerRT.append(D[(D['gameID']== game) & (D['condition'] == 'closer')]['viewerRT'].mean())    \n",
    "    further_viewerRT.append(D[(D['gameID']== game) & (D['condition'] == 'further')]['viewerRT'].mean())     \n",
    "    \n",
    "further_strokes, closer_strokes, further_svgLength, closer_svgLength, \\\n",
    "further_svgStd, closer_svgStd, further_svgLengthPS, closer_svgLengthPS, \\\n",
    "further_drawDuration, closer_drawDuration, further_accuracy, closer_accuracy, \\\n",
    "closer_meanintensity,further_meanintensity, closer_viewerRT, further_viewerRT = map(np.array, \\\n",
    "[further_strokes, closer_strokes, further_svgLength, closer_svgLength,\\\n",
    " further_svgStd, closer_svgStd, further_svgLengthPS, closer_svgLengthPS, \\\n",
    "further_drawDuration, closer_drawDuration, further_accuracy, closer_accuracy, \\\n",
    "closer_meanintensity, further_meanintensity, closer_viewerRT, further_viewerRT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trim_outliers(x):\n",
    "    mu = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    thresh = mu + sd*3\n",
    "    y = [i for i in x if i<thresh]\n",
    "    return y\n",
    "\n",
    "def bootstrap(w,nIter=50000):\n",
    "    boot = []\n",
    "    for i in np.arange(nIter):\n",
    "        boot.append(np.mean(np.random.choice(w,len(w),replace=True)))\n",
    "    boot = np.array(boot) \n",
    "    p = sum(boot<0)/len(boot)*2\n",
    "    lb = np.percentile(boot,2.5)\n",
    "    ub = np.percentile(boot,97.5)\n",
    "    print 'p = ' + str(sum(boot<0)/len(boot)*2)\n",
    "    return boot, p, lb, ub\n",
    "\n",
    "print D.groupby('condition')['numStrokes'].mean()\n",
    "print D.groupby('condition')['mean_intensity'].mean()\n",
    "print D.groupby('condition')['drawDuration'].mean()\n",
    "print D.groupby('condition')['outcome'].mean()\n",
    "print D.groupby('condition')['viewerRT'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,6,1)\n",
    "ax = sns.barplot(data=D,x='condition',y='numStrokes')\n",
    "plt.ylabel('num strokes')\n",
    "plt.subplot(1,6,2)\n",
    "sns.barplot(data=D,x='condition',y='mean_intensity')\n",
    "plt.ylabel('mean pixel intensity')\n",
    "plt.subplot(1,6,3)\n",
    "sns.barplot(data=D,x='condition',y='outcome')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([0,1.01])\n",
    "plt.subplot(1,6,4)\n",
    "sns.barplot(data=D,x='condition',y='drawDuration')\n",
    "plt.ylabel('draw duration (s)')\n",
    "plt.subplot(1,6,5)\n",
    "ax = sns.barplot(data=D,x='condition',y='viewerRT')\n",
    "plt.ylabel('viewer RT (s)')\n",
    "plt.ylim(0,10)\n",
    "plt.subplot(1,6,6)\n",
    "ax = sns.barplot(data=AIC)\n",
    "plt.ylim([13000,14000])\n",
    "plt.ylabel('AIC')\n",
    "plt.tight_layout()\n",
    "if not os.path.exists('./plots'):\n",
    "    os.makedirs('./plots')\n",
    "plt.savefig('./plots/sketchpad_basic_pilot2_taskperformance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## bootstrapped CI's on main task performance measures\n",
    "boot, p, lb, ub = bootstrap(closer_strokes - further_strokes)\n",
    "print p,lb,ub\n",
    "\n",
    "boot, p, lb, ub = bootstrap(closer_meanintensity - further_meanintensity)\n",
    "print p,lb,ub\n",
    "\n",
    "boot, p, lb, ub = bootstrap(closer_drawDuration - further_drawDuration)\n",
    "print p,lb,ub\n",
    "\n",
    "boot, p, lb, ub = bootstrap(closer_drawDuration - further_drawDuration)\n",
    "print p,lb,ub\n",
    "\n",
    "boot, p, lb, ub = bootstrap(closer_viewerRT - further_viewerRT)\n",
    "print p,lb,ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "lb = 0\n",
    "ub = 24\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_strokes,further_strokes,64,(0.8,0.4,0.4))\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('number of strokes')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.subplot(2,2,2)\n",
    "lb = 0\n",
    "ub = 3000\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_svgLength,further_svgLength,64,(0.8,0.4,0.4))\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.tight_layout()\n",
    "plt.title('svg string length')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.subplot(2,2,3)\n",
    "lb = 0\n",
    "ub = 300\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_svgStd,further_svgStd,64,(0.8,0.4,0.4))\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('stroke variability')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.subplot(2,2,4)\n",
    "lb = 0\n",
    "ub = 300\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_svgLengthPS,further_svgLengthPS,64,(0.8,0.4,0.4))\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.tight_layout()\n",
    "plt.title('svg length per stroke')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "save_out = 1\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')\n",
    "if save_out:\n",
    "    save('plots/svg_summary_scatter_{}'.format(iterationName), ext='pdf', close=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "lb = 0\n",
    "ub = 1.03\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_accuracy,further_accuracy,64,(0.8,0.4,0.4))\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.subplot(1,2,2)\n",
    "lb = 0\n",
    "ub = 36\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_drawDuration,further_drawDuration,64,(0.75,0.3,0.2))\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('draw duration')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.tight_layout()\n",
    "save_out = 1\n",
    "if save_out:\n",
    "    save('plots/performance_summary_scatter_{}'.format(iterationName), ext='pdf', close=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_canonical(category):    \n",
    "    stimFile = os.path.join(exp_dir,'stimList_subord.js')\n",
    "    with open(stimFile) as f:\n",
    "        stimList = json.load(f)    \n",
    "    allviews = [i['filename'] for i in stimList if i['basic']==category]\n",
    "    canonical = [a for a in allviews if a[-8:]=='0035.png']    \n",
    "    return canonical\n",
    "\n",
    "def get_actual_pose(subordinate,pose):\n",
    "    stimFile = os.path.join(exp_dir,'stimList_subord.js')\n",
    "    with open(stimFile) as f:\n",
    "        stimList = json.load(f)\n",
    "    inpose = [i['filename'] for i in stimList if (i['subordinate']==subordinate) and (i['pose']==pose)]\n",
    "    return inpose\n",
    "    \n",
    "def get_subord_names(category):\n",
    "    full_names = get_canonical(category)    \n",
    "    return [c.split('_')[2] for c in full_names]\n",
    "\n",
    "def get_basic_names(subordinate):\n",
    "    stimFile = os.path.join(exp_dir,'stimList_subord.js')\n",
    "    with open(stimFile) as f:\n",
    "        stimList = json.load(f)   \n",
    "    allviews = [i['filename'] for i in stimList if i['subordinate']==subordinate]\n",
    "    canonical = [a for a in allviews if a[-8:]=='0035.png']      \n",
    "    return canonical[0].split('_')[0]\n",
    "\n",
    "def build_url_from_category(category):\n",
    "    full_names = get_canonical(category)\n",
    "    url_prefix = 'https://s3.amazonaws.com/sketchloop-images-subord/'\n",
    "    urls = []\n",
    "    for f in full_names:\n",
    "        urls.append(url_prefix + f)\n",
    "    return urls\n",
    "\n",
    "def build_url_from_filenames(filenames):\n",
    "    url_prefix = 'https://s3.amazonaws.com/sketchloop-images-subord/'\n",
    "    urls = []\n",
    "    for f in filenames:\n",
    "        urls.append(url_prefix + f)\n",
    "    return urls\n",
    "\n",
    "def plot_from_url(URL):\n",
    "    file = cStringIO.StringIO(urllib.urlopen(URL).read())\n",
    "    img = Image.open(file)    \n",
    "\n",
    "def plot_gallery(category):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.gridspec as gridspec\n",
    "\n",
    "    plt.figure(figsize = (8,8))\n",
    "    gs1 = gridspec.GridSpec(8, 8)\n",
    "    gs1.update(wspace=0.025, hspace=0.05)\n",
    "\n",
    "    url_prefix = 'https://s3.amazonaws.com/sketchloop-images-subord/'\n",
    "    for (i,c) in enumerate(category):\n",
    "        URL = url_prefix + c\n",
    "        file = cStringIO.StringIO(urllib.urlopen(URL).read())\n",
    "        img = Image.open(file)\n",
    "        p = plt.subplot(3,3,i+1)\n",
    "        plt.imshow(img)\n",
    "        p.get_xaxis().set_ticklabels([])\n",
    "        p.get_yaxis().set_ticklabels([])\n",
    "        p.get_xaxis().set_ticks([])\n",
    "        p.get_yaxis().set_ticks([])\n",
    "        p.set_aspect('equal')\n",
    "        subord = c.split('_')[2]\n",
    "        plt.title(subord)\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## print out sketches with target & distractors from this game\n",
    "import traceback\n",
    "backup_path_images = '/Users/judithfan/Dropbox/stimuli_repository/subordinate_allrotations_6_minified'\n",
    "\n",
    "_valid_gameids = valid_gameids[:3]\n",
    "\n",
    "## get list of all incorrect sketch path names\n",
    "incorrect_trial_paths = []\n",
    "\n",
    "run_this = 0\n",
    "if run_this:\n",
    "#     all_games = click_files\n",
    "    for g in valid_gameids:\n",
    "        print 'Printing out sketches from game: ' + g\n",
    "        _D = D[(D.gameID==g)]\n",
    "        _D = _D.sort_values(by=['target'])\n",
    "        _i = 1\n",
    "        textsize=12\n",
    "        fig = plt.figure(figsize=(16,6))        \n",
    "        for i,_d in _D.iterrows():\n",
    "            imgData = _d['png']\n",
    "            filestr = base64.b64decode(imgData)\n",
    "            target_sketch_dir = os.path.join(analysis_dir,'sketches_pilot2','sketch')\n",
    "            if not os.path.exists(target_sketch_dir):\n",
    "                os.makedirs(target_sketch_dir)\n",
    "            fname = os.path.join(target_sketch_dir,'gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '.png')\n",
    "            with open(fname, \"wb\") as fh:\n",
    "                fh.write(imgData.decode('base64'))\n",
    "            textsize = 16\n",
    "            # first plot the target\n",
    "            im = Image.open(fname)\n",
    "            p = plt.subplot(2,4,1)\n",
    "            plt.imshow(im)\n",
    "            sns.set_style('white')\n",
    "            k = p.get_xaxis().set_ticklabels([])\n",
    "            k = p.get_yaxis().set_ticklabels([])\n",
    "            k = p.get_xaxis().set_ticks([])\n",
    "            k = p.get_yaxis().set_ticks([])        \n",
    "            targetname = _d['target']\n",
    "            distractors = [_d['Distractor1'],_d['Distractor2'],_d['Distractor3']]\n",
    "            full_list = [_d['target'],_d['Distractor1'],_d['Distractor2'],_d['Distractor3']] \n",
    "            outcome = _d['outcome']\n",
    "            if _d['outcome']==0:\n",
    "                incorrect_trial_paths.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '_' + _d['target'] + '.png')            \n",
    "                        \n",
    "            response = _d['response']        \n",
    "            if outcome == 1:\n",
    "                sides = ['bottom','top','right','left']\n",
    "                for s in sides:\n",
    "                    p.spines[s].set_color((0.4,0.8,0.4))\n",
    "                    p.spines[s].set_linewidth(4)                               \n",
    "            else:\n",
    "                sides = ['bottom','top','right','left']\n",
    "                for s in sides:\n",
    "                    p.spines[s].set_color((0.9,0.2,0.2))\n",
    "                    p.spines[s].set_linewidth(4)                      \n",
    "            plt.title(targetname,fontsize=textsize)\n",
    "            plt.ylabel('v:' + response,fontsize=textsize-2)        \n",
    "        \n",
    "            # fig = plt.figure(figsize=(8,3))\n",
    "            for (i,d) in enumerate(full_list):\n",
    "                if os.path.exists(backup_path_images):\n",
    "                    if hasattr(t, 'pose'):\n",
    "                        fn = os.path.join(backup_path_images,get_actual_pose(d,pose)[0])\n",
    "                    else:\n",
    "                        fn = os.path.join(backup_path_images,get_actual_pose(d,35)[0])\n",
    "                else:\n",
    "                    if hasattr(t, 'pose'):\n",
    "                        pose = t['pose']\n",
    "                        URL = build_url_from_filenames(get_actual_pose(d,pose)[0])\n",
    "                    else:\n",
    "                        URL = full_dict[d]\n",
    "                    fn = cStringIO.StringIO(urllib.urlopen(URL).read())\n",
    "                img = Image.open(fn)\n",
    "                p = plt.subplot(2,4,i+5)\n",
    "                plt.imshow(img)\n",
    "                p.get_xaxis().set_ticklabels([])\n",
    "                p.get_yaxis().set_ticklabels([])\n",
    "                p.get_xaxis().set_ticks([])\n",
    "                p.get_yaxis().set_ticks([])\n",
    "                p.set_aspect('equal')   \n",
    "                plt.title(d)\n",
    "\n",
    "            sketch_dir = os.path.join(analysis_dir,'sketches_pilot2','full_display')\n",
    "            if not os.path.exists(sketch_dir):\n",
    "                os.makedirs(os.path.join(analysis_dir,'sketches_pilot2','full_display'))\n",
    "            filepath = os.path.join(sketch_dir,'gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']))\n",
    "            save(filepath, ext='png', close=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save out number of incorrect trial paths\n",
    "print \"Number of incorrect trial paths: {}\".format(str(len(incorrect_trial_paths)))\n",
    "with open('incorrect_trial_paths_pilot2.txt', 'w') as f:\n",
    "    for path in incorrect_trial_paths:\n",
    "        f.write(path + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out sketches in separate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## print out sketches with target & distractors from this game in separate folders\n",
    "import traceback\n",
    "backup_path_images = '/Users/judithfan/Dropbox/stimuli_repository/subordinate_allrotations_6_minified'\n",
    "\n",
    "_valid_gameids = valid_gameids[:3]\n",
    "\n",
    "target_sketch_dir = os.path.join(analysis_dir,'sketches_pilot2','sketch')\n",
    "target_3D_dir = os.path.join(analysis_dir,'sketches_pilot2','target')\n",
    "distractor1_3D_dir = os.path.join(analysis_dir,'sketches_pilot2','distractor1')\n",
    "distractor2_3D_dir = os.path.join(analysis_dir,'sketches_pilot2','distractor2')\n",
    "distractor3_3D_dir = os.path.join(analysis_dir,'sketches_pilot2','distractor3')\n",
    "out_paths = [target_3D_dir,distractor1_3D_dir,distractor2_3D_dir,distractor3_3D_dir]\n",
    "\n",
    "\n",
    "if not os.path.exists(target_3D_dir):\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches_pilot2','target'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches_pilot2','distractor1'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches_pilot2','distractor2'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches_pilot2','distractor3'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches_pilot2','sketch'))    \n",
    "\n",
    "run_this = 1\n",
    "if run_this:\n",
    "    for g in valid_gameids:\n",
    "        print 'Printing out sketches from game: ' + g\n",
    "        _D = D[(D.gameID==g)]\n",
    "        _D = _D.sort_values(by=['target'])\n",
    "        _i = 1\n",
    "        textsize=12\n",
    "        fig = plt.figure(figsize=(16,6))        \n",
    "        for i,_d in _D.iterrows():\n",
    "            imgData = _d['png']\n",
    "            filestr = base64.b64decode(imgData)\n",
    "            if not os.path.exists(target_sketch_dir):\n",
    "                os.makedirs(target_sketch_dir)\n",
    "            fname = os.path.join(target_sketch_dir,'gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '.png')\n",
    "            with open(fname, \"wb\") as fh:\n",
    "                fh.write(imgData.decode('base64'))\n",
    "            im = Image.open(fname)\n",
    "            im.save(fname)\n",
    "\n",
    "            targetname = _d['target']\n",
    "            distractors = [_d['Distractor1'],_d['Distractor2'],_d['Distractor3']]\n",
    "            full_list = [_d['target'],_d['Distractor1'],_d['Distractor2'],_d['Distractor3']]         \n",
    "            \n",
    "            for (i,d) in enumerate(full_list):\n",
    "                if os.path.exists(backup_path_images):\n",
    "                    if hasattr(t, 'pose'):\n",
    "                        fn = os.path.join(backup_path_images,get_actual_pose(d,pose)[0])\n",
    "                    else:\n",
    "                        fn = os.path.join(backup_path_images,get_actual_pose(d,35)[0])\n",
    "                else:\n",
    "                    if hasattr(t, 'pose'):\n",
    "                        pose = _d['pose']\n",
    "                        URL = build_url_from_filenames(get_actual_pose(d,pose)[0])\n",
    "                    else:\n",
    "                        URL = full_dict[d]\n",
    "                    fn = cStringIO.StringIO(urllib.urlopen(URL).read())\n",
    "                fig = plt.figure(figsize=(8,8))                    \n",
    "                im = Image.open(fn)\n",
    "                im = im.resize((256,256), Image.ANTIALIAS).convert('RGB')                                \n",
    "                out_dirs = [target_3D_dir,distractor1_3D_dir,distractor2_3D_dir,distractor3_3D_dir]                \n",
    "                out_path = os.path.join(out_dirs[i],'gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '_' + d + '.png')\n",
    "                im.save(out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data again to prep for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data.csv'))\n",
    "DUNFIL = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data_unfiltered.csv'))\n",
    "\n",
    "# filter out incorrect and invalid trials as well\n",
    "incorrects = pd.read_csv('./incorrect_trial_paths_pilot2.txt',header=None)[0].values\n",
    "invalids = pd.read_csv('./invalid_trial_paths_pilot2.txt',header=None)[0].values\n",
    "\n",
    "def add_fnames(D):\n",
    "    fname = []\n",
    "    for i,_d in D.iterrows():\n",
    "        fname.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '_' + _d['target'] +'.png')    \n",
    "    D = D.assign(fname=pd.Series(fname).values)  \n",
    "\n",
    "    fname_no_target = []\n",
    "    for i,_d in D.iterrows():\n",
    "        fname_no_target.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) +'.png')    \n",
    "    D = D.assign(fname_no_target=pd.Series(fname_no_target).values) \n",
    "    return D\n",
    "\n",
    "def filter_out_incorrect(D, incorrects):\n",
    "    D = D[~D['fname'].isin(incorrects)]\n",
    "    return D\n",
    "\n",
    "def filter_out_invalids(D, invalids):\n",
    "    D = D[~D['fname_no_target'].isin(invalids)] \n",
    "    return D\n",
    "    \n",
    "## add some filename columns\n",
    "D = add_fnames(D)\n",
    "DUNFIL = add_fnames(DUNFIL) ## version of dataframe with ALL trials, garbage games, incorrect trials, invalid trials\n",
    "\n",
    "DNOINC = filter_out_incorrect(DUNFIL, incorrects) ## save version of D containing with incorrect trials filtered out only\n",
    "DNOINV = filter_out_invalids(DUNFIL, invalids) ## save version of D containing with invalid trials filtered out only\n",
    "D = filter_out_invalids(filter_out_incorrect(D, incorrects), invalids) ## both kinds of garbage filtered out\n",
    "\n",
    "print np.shape(D)\n",
    "print str(np.shape(D)[0]) + ' records in merged dataframe'\n",
    "\n",
    "print '{} incorrect trials'.format(len(incorrects))\n",
    "print '{} invalid trials'.format(len(invalids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '{} trials with NO GARBAGE filtered out'.format(DUNFIL.shape[0])\n",
    "print '{} trials with incorrects filtered out'.format(DNOINC.shape[0])\n",
    "print '{} trials with invalids filtered out'.format(DNOINV.shape[0])\n",
    "print '{} trials with ALL GARBAGE filtered out'.format(D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## now assign sketch_label and class_label for the other versions of D\n",
    "def add_extra_label_columns(D):\n",
    "    sketch_label = [(i[-12:] + '_' + str(j)) for i,j in zip(D['gameID'].values,D['trialNum'].values)]\n",
    "    D = D.assign(sketch_label=pd.Series(sketch_label).values)\n",
    "\n",
    "    # add class label\n",
    "    category = []\n",
    "    classes = ['bird','car','chair','dog']\n",
    "    for i,d in D.iterrows():\n",
    "        category.append(h.objcat[d['target']])\n",
    "    D = D.assign(category=pd.Series(category).values)\n",
    "    return D\n",
    "\n",
    "D = add_extra_label_columns(D)\n",
    "DUNFIL = add_extra_label_columns(DUNFIL)\n",
    "DNOINC = add_extra_label_columns(DNOINC)\n",
    "DNOINV = add_extra_label_columns(DNOINV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Visualize distance distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_dists = './strict-similarity-pragmatics-fixedpose-augmented-splitbycontext_conv4_2.json'\n",
    "_dists = pd.read_json(path_to_dists)\n",
    "dists = _dists.transpose()\n",
    "x = _dists.columns.values\n",
    "y = [i.split('_')[-1] for i in x]\n",
    "lookup_table = dict(zip(y,x))\n",
    "reverse_lookup = dict(zip(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dT = []\n",
    "dD1 = []\n",
    "dD2 = []\n",
    "dD3 = []\n",
    "for i, _d in D.iterrows():\n",
    "    sketch = _d['sketch_label']\n",
    "    pose = int(_d['pose'])\n",
    "    target = lookup_table[_d['target']]\n",
    "    distractor1 = lookup_table[_d['Distractor1']]\n",
    "    distractor2 = lookup_table[_d['Distractor2']]\n",
    "    distractor3 = lookup_table[_d['Distractor3']]\n",
    "    dT.append(dists[sketch][target])\n",
    "    dD1.append(dists[sketch][distractor1])\n",
    "    dD2.append(dists[sketch][distractor2])\n",
    "    dD3.append(dists[sketch][distractor3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = D.assign(dT=pd.Series(dT).values)\n",
    "D = D.assign(dD1=pd.Series(dD1).values)\n",
    "D = D.assign(dD2=pd.Series(dD2).values)\n",
    "D = D.assign(dD3=pd.Series(dD3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out training examples\n",
    "# test_examples = pd.read_csv('./pilot2_augmented2_test_examples.txt',header=None)[0].values\n",
    "# test_examples = [i.split('.')[0] + '.png' for i in test_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "_D = D[(D.condition=='closer') & (D['fname'].isin(test_examples))]\n",
    "distractor_dists = np.hstack((_D.dD1.values,_D.dD2.values,_D.dD3.values))\n",
    "sns.kdeplot(distractor_dists, shade=True, color=(0.3,0.3,0.3),label='distractors')\n",
    "sns.kdeplot(_D.dT.values, shade=True, color=(0.9,0.7,0.1),label='target')\n",
    "plt.ylim([0,7])\n",
    "plt.xlim([-1,1])\n",
    "plt.xlabel('distance')\n",
    "plt.title('close')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "_D = D[(D.condition=='further') & (D['fname'].isin(test_examples))]\n",
    "distractor_dists = np.hstack((_D.dD1.values,_D.dD2.values,_D.dD3.values))\n",
    "sns.kdeplot(distractor_dists, shade=True, color=(0.3,0.3,0.3),label='distractors')\n",
    "sns.kdeplot(_D.dT.values, shade=True, color=(0.9,0.7,0.1),label='target')\n",
    "plt.ylim([0,7])\n",
    "plt.xlim([-1,1])\n",
    "plt.xlabel('distance')\n",
    "plt.title('far')\n",
    "\n",
    "plt.suptitle('fixedpose - augmented - splitbycontext - test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(12,12))\n",
    "for i,cl in enumerate(classes):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    _D = D[(D['fname'].isin(test_examples)) & (D['category']==cl)]\n",
    "    distractor_dists = np.hstack((_D.dD1.values,_D.dD2.values,_D.dD3.values))\n",
    "    sns.kdeplot(distractor_dists, shade=True, color=(0.3,0.3,0.3),label='distractors')\n",
    "    sns.kdeplot(_D.dT.values, shade=True, color=(0.9,0.7,0.1),label='target')\n",
    "    plt.ylim([0,7])\n",
    "    plt.xlim([-1,1])\n",
    "    if i>1:\n",
    "        plt.xlabel('distance')\n",
    "    plt.title('{}'.format(cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing to make bdaInput csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_bdaInput_csv(D,filtration_level):\n",
    "    # filter out training examples\n",
    "    test_examples = pd.read_csv('./pilot2_augmented_splitbycontext_test_examples.txt',header=None)[0].values\n",
    "    test_examples = [i.split('.')[0] + '.png' for i in test_examples]\n",
    "    keep_examples = test_examples\n",
    "\n",
    "    D0 = D[D['fname'].isin(keep_examples)]\n",
    "    print('Shape of D0: {}'.format(D0.shape))\n",
    "\n",
    "    ## generate lists to compose new bdaInput CSV\n",
    "    _sketchLabel = []\n",
    "    _Condition = []\n",
    "    _Target = []\n",
    "    _Distractor1 = []\n",
    "    _Distractor2 = []\n",
    "    _Distractor3 = []\n",
    "    _coarseGrainedSketchInfo = [] # condition_objectName ... e.g., further_knob\n",
    "    for i, _d in D0.iterrows():\n",
    "        _sketchLabel.append(_d['sketch_label'])\n",
    "        _Condition.append(_d['condition'])    \n",
    "        _Target.append(lookup_table[_d['target']])\n",
    "        distractor1 = lookup_table[_d['Distractor1']]\n",
    "        distractor2 = lookup_table[_d['Distractor2']]\n",
    "        distractor3 = lookup_table[_d['Distractor3']]\n",
    "        d_list = sorted([distractor1, distractor2, distractor3])\n",
    "        _Distractor1.append(d_list[0])\n",
    "        _Distractor2.append(d_list[1])    \n",
    "        _Distractor3.append(d_list[2])  \n",
    "        _coarseGrainedSketchInfo.append('{}_{}'.format(_d['condition'],_d['target'])) \n",
    "\n",
    "    D2 = pd.DataFrame([_Condition,_sketchLabel,_Target,_Distractor1,_Distractor2,_Distractor3,_coarseGrainedSketchInfo])\n",
    "    D2 = D2.transpose()\n",
    "    D2.columns = ['condition','sketchLabel','Target','Distractor1','Distractor2','Distractor3','coarseGrainedSketchInfo']\n",
    "    print D2.shape\n",
    "    if len(filtration_level)==0:\n",
    "        D2.to_csv('../models/bdaInput/sketchData_fixedPose_splitbycontext_augmented2_pilot2.csv')\n",
    "    else:  \n",
    "        D2.to_csv('../models/bdaInput/sketchData_fixedPose_splitbycontext_augmented2_pilot2_{}.csv'.format(filtration_level))\n",
    "    print 'Saved out bdaInput CSV ... {}'.format(filtration_level) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_bdaInput_csv(D,'')\n",
    "generate_bdaInput_csv(DNOINC,'no_incorrect')\n",
    "generate_bdaInput_csv(DNOINV,'no_invalid')\n",
    "generate_bdaInput_csv(DUNFIL,'unfiltered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = pd.read_csv('../models/bdaInput/sketchData_fixedPose_splitbycontext_augmented2_pilot2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sumlogprob(a,b):\n",
    "    if (a > b):\n",
    "        return a + np.log1p(np.exp(b-a))\n",
    "    else:\n",
    "        return b + np.log1p(np.exp(a-b))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "which_feat = 'fixedpose_aug2_alldata'\n",
    "\n",
    "if which_feat == 'varypose_nonaug':\n",
    "    P = pd.read_csv('./RSA/bdaOutput/testingParams_alldata.csv')\n",
    "elif which_feat == 'fixedpose_nonaug_closeonly':\n",
    "    P = pd.read_csv('./RSA/bdaOutput/testingParams_closeonly_fixedpose.csv')\n",
    "elif which_feat == 'fixedpose_aug_closeonly':\n",
    "    P = pd.read_csv('./RSA/bdaOutput/testingParams_closeonly_fixedpose_augmented.csv')\n",
    "elif which_feat == 'fixedpose_aug2_alldata':\n",
    "    P = pd.read_csv('./RSA/bdaOutput/testingParams_testdata_fixedpose_augmented2.csv')\n",
    "    \n",
    "# filter out rows where posterior probability is -Infinity\n",
    "# P = P[P.posteriorProb!='-Infinity']\n",
    "print np.shape(P)\n",
    "\n",
    "X = P.groupby(['similarityMetric', 'speakerModel'])['logLikelihood']\n",
    "Y = X.apply(lambda x: reduce(sumlogprob,x) - np.log(len(x)))\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"Paired\")\n",
    "fig = plt.figure(figsize=(26,8))\n",
    "seq = [('strict-mid-pragmatics-augmented2','S0'),('strict-mid-pragmatics-augmented2','S1'),('nonstrict-high-sketchy','S0'),('nonstrict-high-sketchy','S1')]\n",
    "sns.barplot(data=Y.transpose(),palette=colors, order = seq)\n",
    "# plt.ylim([-1400,-600])\n",
    "plt.ylabel('log likelihood')\n",
    "plt.title('model comparison: all test data',fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# P = pd.read_csv('./RSA/bdaOutput/testingParams_testdata_fixedpose.csv')\n",
    "# # filter out rows where posterior probability is -Infinity\n",
    "# # P = P[P.posteriorProb!='-Infinity']\n",
    "# print np.shape(P)\n",
    "\n",
    "# X = P.groupby(['similarityMetric', 'speakerModel'])['logLikelihood']\n",
    "# Y = X.apply(lambda x: reduce(sumlogprob,x) - np.log(len(x)))\n",
    "# Y = pd.DataFrame(Y)\n",
    "\n",
    "# sns.set_context('talk')\n",
    "# colors = sns.color_palette(\"Paired\")\n",
    "# fig = plt.figure(figsize=(16,4))\n",
    "# seq = [('strict-mid-pragmatics-augmented','S0'),('strict-mid-pragmatics-augmented','S1'),('strict-mid-pragmatics','S0'),('strict-mid-pragmatics','S1'),('nonstrict-high-sketchy','S0'),('nonstrict-high-sketchy','S1')]\n",
    "# sns.barplot(data=Y.transpose(),palette=colors, order = seq)\n",
    "# plt.ylim([-9000,-8000])\n",
    "# plt.ylabel('log likelihood')\n",
    "# plt.title('model comparison: held out data (majority far trials)',fontsize=24)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### latest set of S1/S0 model log-likelihoods\n",
    "\n",
    "combined= -6658\n",
    "S1= -6720\n",
    "S0= -6734\n",
    "\n",
    "S0_AIC = -2*S0\n",
    "S1_AIC = -2*S1\n",
    "combined_AIC = 2 - 2*combined\n",
    "\n",
    "LL = pd.DataFrame([S0,S1,combined])\n",
    "LL = LL.transpose()\n",
    "LL.columns = ['figurative','contrastive','communicative']\n",
    "\n",
    "AIC = pd.DataFrame([S0_AIC,S1_AIC,combined_AIC])\n",
    "AIC = AIC.transpose()\n",
    "AIC.columns = ['figurative','contrastive','communicative']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.subplot(111)\n",
    "sns.barplot(data=AIC)\n",
    "plt.ylim([13000,13500])\n",
    "plt.ylabel('AIC')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/model_comparison_for_vss_abstract.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
