{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT: preprocessed group data CSV from mongo (see pilot2_analysis_sketchpad_basic)\n",
    "## OUTPUT: full set of bdaInput files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__list of bdaInpput files__: \n",
    "* sketchData CSV (generated inside generate_bdaInput_csv)\n",
    "* test_examples TXT/JSON/CSV (generated inside generate_bdaInput_csv)\n",
    "* costs JSON\n",
    "* condition-lookup JSON\n",
    "* similarity JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Because using human perceptual encoder, we need to generate similarity json from the annotation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in human annotations csv (prepped in pilot2_analysis_sketchpad_basic_recog.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('./sketchpad_basic_recog_group_data_2.csv')\n",
    "print 'Shape of un-augmented (additional columns) annotation csv: {}'.format(X.shape)\n",
    "\n",
    "X = pd.read_csv('./sketchpad_basic_recog_group_data_2_augmented.csv')\n",
    "print 'Shape of augmented annotation csv: {}'.format(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep similarity jsons for evaluation by passing forward to RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format for json is a dictionary of dictionaries, where each top-level key refers to one of the renders, e.g. \"cuckoo\". For each render, you can look up the similarity with each sketch, referenced with an abbreviated ID taken by trimming the last 12-character string, and appending an underscore, and the trial number. E.g., 'gameID_9903-d6e6a9ff-a878-4bee-b2d5-26e2e239460a_trial_9.npy' ==> '26e2e239460a_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_json(json_path):\n",
    "    with open(json_path) as fp:\n",
    "        data = json.load(fp)  \n",
    "    return data\n",
    "\n",
    "def simplify_sketch(path): ## example path: 'gameID_9903-d6e6a9ff-a878-4bee-b2d5-26e2e239460a_trial_9.npy' ==> '26e2e239460a_9'\n",
    "    path = '_'.join(os.path.splitext(os.path.basename(path))[0].split('_')[1:])\n",
    "    path = path.split('-')[-1]\n",
    "    path = path.replace('_trial', '')\n",
    "    return path\n",
    "\n",
    "from collections import Counter\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "## get standardized object list\n",
    "categories = ['bird','car','chair','dog']\n",
    "obj_list = []\n",
    "for cat in categories:\n",
    "    for i,j in h.objcat.iteritems():\n",
    "        if j==cat:\n",
    "            obj_list.append(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    ## define list of renders and sketches\n",
    "    render_list = obj_list\n",
    "    sketch_list = np.unique(X['sketchID'])\n",
    "\n",
    "    out_json = {}\n",
    "    for i, this_render in enumerate(render_list):\n",
    "        print i, this_render\n",
    "        out_json[this_render] = {}\n",
    "        for j,this_sketch in enumerate(sketch_list):        \n",
    "            counts = np.zeros(len(obj_list)) ## initialize the probability vector\n",
    "            choices = X[X['sketchID']==this_sketch]['choice'].values ## get list of all choices\n",
    "\n",
    "            ## get counter dictionary\n",
    "            cdict = Counter(choices)\n",
    "            ## populate count vector accordingly\n",
    "            for i,o in enumerate(obj_list):\n",
    "                if o in cdict:\n",
    "                    counts[i] = cdict[o]\n",
    "\n",
    "            ## get probability vector by dividing by sum\n",
    "            prob = counts/np.sum(counts)\n",
    "            out_json[this_render][this_sketch] = prob[i]    \n",
    "\n",
    "    ## output json in the same format as the other similarity jsons\n",
    "    output_path = '../models/refModule/json/similarity-human_full25k-centroid.json'\n",
    "    with open(output_path, 'wb') as fp:\n",
    "        json.dump(out_json, fp)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate bdaInput CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "iterationName = 'pilot2'\n",
    "exp_path = './'\n",
    "analysis_dir = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','data',exp_path))\n",
    "exp_dir = './'\n",
    "sketch_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','analysis',exp_path,'sketches','pilot2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data.csv'))\n",
    "DUNFIL = pd.read_csv(os.path.join(analysis_dir,'sketchpad_basic_pilot2_group_data_unfiltered.csv'))\n",
    "\n",
    "# filter out incorrect and invalid trials as well\n",
    "incorrects = pd.read_csv('./incorrect_trial_paths_pilot2.txt',header=None)[0].values\n",
    "invalids = pd.read_csv('./invalid_trial_paths_pilot2.txt',header=None)[0].values\n",
    "\n",
    "def add_fnames(D):\n",
    "    fname = []\n",
    "    for i,_d in D.iterrows():\n",
    "        fname.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '_' + _d['target'] +'.png')    \n",
    "    D = D.assign(fname=pd.Series(fname).values)  \n",
    "\n",
    "    fname_no_target = []\n",
    "    for i,_d in D.iterrows():\n",
    "        fname_no_target.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) +'.png')    \n",
    "    D = D.assign(fname_no_target=pd.Series(fname_no_target).values) \n",
    "    return D\n",
    "\n",
    "def filter_out_incorrect(D, incorrects):\n",
    "    D = D[~D['fname'].isin(incorrects)]\n",
    "    return D\n",
    "\n",
    "def filter_out_invalids(D, invalids):\n",
    "    D = D[~D['fname_no_target'].isin(invalids)] \n",
    "    return D\n",
    "    \n",
    "## add some filename columns\n",
    "D = add_fnames(D)\n",
    "DUNFIL = add_fnames(DUNFIL) ## version of dataframe with ALL trials, garbage games, incorrect trials, invalid trials\n",
    "\n",
    "DNOINC = filter_out_incorrect(DUNFIL, incorrects) ## save version of D containing with incorrect trials filtered out only\n",
    "DNOINV = filter_out_invalids(DUNFIL, invalids) ## save version of D containing with invalid trials filtered out only\n",
    "D = filter_out_invalids(filter_out_incorrect(D, incorrects), invalids) ## both kinds of garbage filtered out\n",
    "\n",
    "print np.shape(D)\n",
    "print str(np.shape(D)[0]) + ' records in merged dataframe'\n",
    "\n",
    "print '{} incorrect trials'.format(len(incorrects))\n",
    "print '{} invalid trials'.format(len(invalids))\n",
    "print ' '\n",
    "print '{} trials with NO GARBAGE filtered out'.format(DUNFIL.shape[0])\n",
    "print '{} trials with incorrects filtered out'.format(DNOINC.shape[0])\n",
    "print '{} trials with invalids filtered out'.format(DNOINV.shape[0])\n",
    "print '{} trials with ALL GARBAGE filtered out'.format(D.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## now assign sketchID and class_label for the other versions of D\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "def add_extra_label_columns(D):\n",
    "    sketchID = [(i[-12:] + '_' + str(j)) for i,j in zip(D['gameID'].values,D['trialNum'].values)]\n",
    "    D = D.assign(sketchID=pd.Series(sketchID).values)\n",
    "\n",
    "    # add class label\n",
    "    category = []\n",
    "    classes = ['bird','car','chair','dog']\n",
    "    for i,d in D.iterrows():\n",
    "        category.append(h.objcat[d['target']])\n",
    "    D = D.assign(category=pd.Series(category).values)\n",
    "    return D\n",
    "\n",
    "D = add_extra_label_columns(D)\n",
    "DUNFIL = add_extra_label_columns(DUNFIL)\n",
    "DNOINC = add_extra_label_columns(DNOINC)\n",
    "DNOINV = add_extra_label_columns(DNOINV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_bdaInput_csv(D,filtration_level,train_test_split=True,\n",
    "                          adaptor_type='human_full25k',\n",
    "                          split_type='splitbyobject'):\n",
    "\n",
    "    ### filter out training examples if using a trained (not human) encoder and if train_test_split==True\n",
    "    if (train_test_split==True):        \n",
    "        test_examples = pd.read_json('pilot2_{}_test_examples.json'.format(adaptor_type),orient='records')\n",
    "        test_examples = list(test_examples[0].values)\n",
    "        test_examples = [i.split('.')[0] + '.png' for i in test_examples]                \n",
    "        keep_examples = test_examples \n",
    "    else:\n",
    "        keep_examples = D['fname_no_target'].values ## keep all datapoints\n",
    "\n",
    "    D0 = D[D['fname_no_target'].isin(keep_examples)]\n",
    "\n",
    "    ## generate lists to compose new bdaInput CSV\n",
    "    _sketchLabel = []\n",
    "    _Condition = []\n",
    "    _Target = []\n",
    "    _Distractor1 = []\n",
    "    _Distractor2 = []\n",
    "    _Distractor3 = []\n",
    "    _coarseGrainedSketchInfo = [] # condition_objectName ... e.g., further_knob\n",
    "    for i, _d in D0.iterrows():\n",
    "        _sketchLabel.append(_d['sketchID'])\n",
    "        _Condition.append(_d['condition']) \n",
    "        _Target.append(_d['target'])\n",
    "        distractor1 = _d['Distractor1']\n",
    "        distractor2 = _d['Distractor2']\n",
    "        distractor3 = _d['Distractor3']      \n",
    "        \n",
    "        d_list = sorted([distractor1, distractor2, distractor3])\n",
    "        _Distractor1.append(d_list[0])\n",
    "        _Distractor2.append(d_list[1])    \n",
    "        _Distractor3.append(d_list[2])  \n",
    "        _coarseGrainedSketchInfo.append('{}_{}'.format(_d['condition'],_d['target'])) \n",
    "\n",
    "    D2 = pd.DataFrame([_Condition,_sketchLabel,_Target,_Distractor1,_Distractor2,_Distractor3,_coarseGrainedSketchInfo])\n",
    "    D2 = D2.transpose()\n",
    "    D2.columns = ['condition','sketchLabel','Target','Distractor1','Distractor2','Distractor3','coarseGrainedSketchInfo']\n",
    "    print '{} datapoints x {} columns'.format(D2.shape[0],D2.shape[1])\n",
    "    \n",
    "    if (train_test_split==True):        \n",
    "        print 'saving CSV with only test data'\n",
    "        if len(filtration_level)==0:\n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2.csv'.format(split_type,adaptor_type))\n",
    "        else:  \n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2_{}.csv'.format(split_type,adaptor_type,filtration_level))\n",
    "    else: ## run bda on ALL datapoints (not just test split)\n",
    "        print 'saving CSV including all datapoints'\n",
    "        if len(filtration_level)==0:\n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_alldata_{}_pilot2.csv'.format(adaptor_type))\n",
    "        else:  \n",
    "            D2.to_csv('../models/bdaInput/sketchData_fixedPose_alldata_{}_pilot2_{}.csv'.format(adaptor_type,filtration_level))        \n",
    "    print 'Saved out bdaInput CSV ... {}'.format(filtration_level) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMILARITY FUNCTION PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## params\n",
    "adaptor_type = 'human_full25k'\n",
    "split_type = 'splitbyobject'    ### to compare with sketch_unroll_full25k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## only generate these CSV's if using a learned encoder\n",
    "\n",
    "# first split versions\n",
    "generate_bdaInput_csv(D,'',adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINC,'no_incorrect',adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINV,'no_invalid',adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DUNFIL,'unfiltered',adaptor_type = adaptor_type,split_type = split_type)    \n",
    "\n",
    "# now alldata versions\n",
    "generate_bdaInput_csv(D,'',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINC,'no_incorrect',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DNOINV,'no_invalid',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)\n",
    "generate_bdaInput_csv(DUNFIL,'unfiltered',train_test_split=False,adaptor_type = adaptor_type,split_type = split_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove cost outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load data in again and filter out cost outliers\n",
    "\n",
    "def remove_outliers(X,column):\n",
    "    mu = np.mean(X[column].values)\n",
    "    sd = np.std(X[column].values)\n",
    "    thresh = mu + 5*sd        \n",
    "    X = X.drop(X[X[column] > thresh].index)\n",
    "    return X\n",
    " \n",
    "## make copy of D that has cost outliers removed    \n",
    "D2 = remove_outliers(D,'drawDuration')    \n",
    "D2 = remove_outliers(D2,'mean_intensity')\n",
    "D2 = remove_outliers(D2,'numStrokes')\n",
    "\n",
    "# print D2.shape\n",
    "\n",
    "splits = ['splitbyobject','alldata']\n",
    "    \n",
    "for split in splits:\n",
    "    ### subset drawing data csv by sketches that are accounted for here (i.e., that were not cost outliers)\n",
    "    B = pd.read_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2.csv'.format(split_type,adaptor_type))    \n",
    "#     print B.shape\n",
    "\n",
    "    remaining_sketches = list(np.unique(D2['sketchID'].values))\n",
    "    _B = B[B['sketchLabel'].isin(remaining_sketches)]\n",
    "#     print _B.shape\n",
    "    _B.to_csv('../models/bdaInput/sketchData_fixedPose_{}_{}_pilot2_costOutliersRemoved.csv'.format(split,adaptor_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate cost dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,k=1,x0=0.5):\n",
    "    return 1 / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "def add_rescaled_metric(X,metric,transform='maxnorm',k=5):\n",
    "    '''\n",
    "    input: X is a data frame, metric is the name of one of the (cost) metrics that you want to scale between 0 and 1\n",
    "            transform options include:\n",
    "                :'maxnorm', which means dividing each value by maximum in list\n",
    "                :'minmaxnorm', look at it\n",
    "                :'sigmoid', which means passing each value through logistic function with mean\n",
    "    output: X with additional column that has the rescaled metric\n",
    "    '''\n",
    "    if metric=='drawDuration': ## if handling drawDuration, log first -- no wait, maybe not \n",
    "        vals = X[metric].values\n",
    "    else:\n",
    "        vals = X[metric].values\n",
    "    X['vals'] = vals\n",
    "    if transform=='maxnorm':\n",
    "        top_val = np.max(vals)\n",
    "        rescaled_val = []\n",
    "        for i,d in X.iterrows():\n",
    "            rescaled_val.append(d['vals']/top_val)\n",
    "    elif transform=='minmaxnorm':\n",
    "        bottom_val = np.min(vals)\n",
    "        top_val = np.max(vals)\n",
    "        rescaled_val = []\n",
    "        for i,d in X.iterrows():\n",
    "            rescaled_val.append((d['vals']-bottom_val)/(top_val-bottom_val))        \n",
    "    elif transform=='sigmoid':\n",
    "        median_val = np.median(vals)\n",
    "        rescaled_val = []\n",
    "        for i,d in X.iterrows():\n",
    "            rescaled_val.append(sigmoid(d['vals'],k=k,x0=median_val))\n",
    "    X['rescaled_{}'.format(metric)] = rescaled_val          \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## actually add rescaled metric\n",
    "D2 = add_rescaled_metric(D2,'numStrokes',transform='minmaxnorm')\n",
    "D2 = add_rescaled_metric(D2,'mean_intensity',transform='minmaxnorm')\n",
    "D2 = add_rescaled_metric(D2,'drawDuration',transform='minmaxnorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## generate cost dictionaries to try out with pragmatics model\n",
    "print len(np.unique(D2['sketchID'].values))\n",
    "sketchID_list = np.unique(D2['sketchID'].values)\n",
    "metrics = ['drawDuration','mean_intensity','numStrokes']\n",
    "\n",
    "for metric in metrics:    \n",
    "    print metric\n",
    "    cost_json = {}\n",
    "    for i,d in enumerate(sketchID_list):\n",
    "        assert len(np.unique(D2[D2['sketchID']==d]['rescaled_{}'.format(metric)].values))==1\n",
    "        cost_json[d] = D2[D2['sketchID']==d]['rescaled_{}'.format(metric)].values[0]    \n",
    "\n",
    "    ## output json in the same format as the other cost json\n",
    "    output_path = '../models/refModule/json/costs-fixedPose96-{}.json'.format(metric)\n",
    "    with open(output_path, 'wb') as fp:\n",
    "        json.dump(cost_json, fp)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate condition-lookup.json to be able to pair sketches with condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## generate condition-lookup.json to be able to pair sketches with condition\n",
    "cond_json = {}\n",
    "sketchID_list = np.unique(D2['sketchID'].values)\n",
    "for i,d in enumerate(sketchID_list):\n",
    "    cond = D2[D2['sketchID']==d]['condition'].values[0]\n",
    "    obj = D2[D2['sketchID']==d]['target'].values[0]\n",
    "    cond_json[d] = '{}_{}'.format(cond,obj)\n",
    "    \n",
    "## output json in the same format as the other cost json\n",
    "output_path = '../models/bdaInput/condition-lookup.json'\n",
    "with open(output_path, 'wb') as fp:\n",
    "    json.dump(cond_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
