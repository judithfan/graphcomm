{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'analysis_helpers' from 'analysis_helpers.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "\n",
    "## get standardized object list\n",
    "categories = ['bird','car','chair','dog']\n",
    "obj_list = []\n",
    "for cat in categories:\n",
    "    for i,j in h.objcat.iteritems():\n",
    "        if j==cat:\n",
    "            obj_list.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "iterationName = 'pilot2'\n",
    "exp_path = './'\n",
    "analysis_dir = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','data',exp_path))\n",
    "exp_dir = './'\n",
    "sketch_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','analysis',exp_path,'sketches','pilot2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['sketchpad_basic_recog']\n",
    "\n",
    "stimdb = conn['stimuli']\n",
    "stimcoll = stimdb['sketchpad_basic_pilot2_sketches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849 sketches in the stimuli db that have been retrieved at least once\n",
      "7720 records in the recognition experiment database\n"
     ]
    }
   ],
   "source": [
    "## How many sketches have been retrieved at least once? equivalent to: coll.find({'numGames':{'$exists':1}}).count()\n",
    "x = stimcoll.find({'numGames':{'$gte':0}}).count()\n",
    "y = coll.count()\n",
    "print '{} sketches in the stimuli db that have been retrieved at least once'.format(x)\n",
    "print '{} records in the recognition experiment database'.format(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess recognition task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 7709 records analyzed.\n",
      "500 out of 7709 records analyzed.\n",
      "1000 out of 7709 records analyzed.\n",
      "1500 out of 7709 records analyzed.\n",
      "2000 out of 7709 records analyzed.\n",
      "2500 out of 7709 records analyzed.\n",
      "3000 out of 7709 records analyzed.\n",
      "3500 out of 7709 records analyzed.\n",
      "4000 out of 7709 records analyzed.\n",
      "4500 out of 7709 records analyzed.\n",
      "5000 out of 7709 records analyzed.\n",
      "5500 out of 7709 records analyzed.\n",
      "Something went wrong with 7699-7141d5a7-5a42-42e7-85dc-ae36f351bfda 47\n",
      "6000 out of 7709 records analyzed.\n",
      "6500 out of 7709 records analyzed.\n",
      "7000 out of 7709 records analyzed.\n",
      "7500 out of 7709 records analyzed.\n"
     ]
    }
   ],
   "source": [
    "## retrieve records from db\n",
    "## notes: \n",
    "## pilot0 = no feedback onscreen\n",
    "## pilot1 = bonus point counter onscreen\n",
    "\n",
    "a = coll.find({'iterationName': {'$in': ['pilot0', 'pilot1']}}).sort('gameID')\n",
    "\n",
    "## make lists from db\n",
    "gameID = []\n",
    "target = []\n",
    "choice = []\n",
    "correct = []\n",
    "correct_class = []\n",
    "rt = []\n",
    "fname = []\n",
    "\n",
    "d1 = []\n",
    "d2 = []\n",
    "d3 = []\n",
    "target_category = []\n",
    "chosen_category = []\n",
    "condition = []\n",
    "drawDuration = []\n",
    "original_gameID = []\n",
    "viewer_correct = []\n",
    "viewer_choice = []\n",
    "viewer_RT = []\n",
    "mean_intensity = []\n",
    "num_strokes = []\n",
    "\n",
    "bad_sessions = ['1571-00d11ddf-96e7-4aae-ba09-1a338b328c0e','9770-2f360e9a-7a07-4026-9c36-18b558c1da21']\n",
    "\n",
    "counter = 0\n",
    "for rec in a:\n",
    "    if rec['gameID'] not in bad_sessions:\n",
    "        try:\n",
    "            if counter%500==0:\n",
    "                print '{} out of {} records analyzed.'.format(counter,a.count())\n",
    "            if rec['target'] is not None:\n",
    "                gameID.append(rec['gameID'])\n",
    "                target.append(rec['target'])\n",
    "                choice.append(rec['choice'])\n",
    "                correct.append(rec['correct'])\n",
    "                rt.append(rec['rt'])\n",
    "                f = rec['sketch'].split('/')[-1]\n",
    "                fname.append(f)\n",
    "                chosen_category.append(h.objcat[rec['choice']])\n",
    "\n",
    "                ## match up with corresponding record in stimuli collection\n",
    "                b = stimcoll.find({'fname_no_target':f})[0]\n",
    "                assert stimcoll.find({'fname_no_target':f}).count()==1\n",
    "                d1.append(b['Distractor1'])\n",
    "                d2.append(b['Distractor2'])\n",
    "                d3.append(b['Distractor2'])\n",
    "                target_category.append(b['category'])\n",
    "                correct_class.append(h.objcat[rec['choice']]==b['category'])\n",
    "                condition.append(b['condition'])\n",
    "                drawDuration.append(b['drawDuration'])\n",
    "                original_gameID.append(b['gameID'])\n",
    "                viewer_correct.append(b['outcome'])\n",
    "                viewer_choice.append(b['response'])\n",
    "                viewer_RT.append(b['viewerRT'])\n",
    "                mean_intensity.append(b['mean_intensity'])  \n",
    "                num_strokes.append(b['numStrokes'])    \n",
    "                counter += 1\n",
    "        except:\n",
    "            print 'Something went wrong with {} {}'.format(rec['gameID'],rec['trialNum'])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## organize data into dataframe\n",
    "X = pd.DataFrame([gameID,target,choice,correct,rt,fname,d1,d2,d3,target_category,chosen_category,condition,drawDuration, \\\n",
    "                 original_gameID,viewer_correct,viewer_choice,viewer_RT,mean_intensity,num_strokes,correct_class])\n",
    "X = X.transpose()\n",
    "X.columns = ['gameID','target','choice','correct','rt','fname','d1','d2','d3','target_category','chosen_category','condition','drawDuration', \\\n",
    "            'original_gameID','viewer_correct','viewer_choice','viewer_RT','mean_intensity','num_strokes','correct_class']\n",
    "print '{} annotations saved.'.format(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7017 annotations retained.\n"
     ]
    }
   ],
   "source": [
    "## remove NaN rows from data matrix (no target recorded)\n",
    "X = X[X['target'].isin(obj_list)]\n",
    "\n",
    "## filter out responses that took too long, or too short\n",
    "too_fast = 1000\n",
    "too_slow = 20000\n",
    "X = X[(X['rt']>=too_fast) & (X['rt']<=too_slow)]\n",
    "\n",
    "print '{} annotations retained.'.format(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save out to CSV\n",
    "X.to_csv('./sketchpad_basic_recog_group_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic performance measures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./plots'):\n",
    "    os.makedirs('./plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition\n",
      "closer     0.541994\n",
      "further    0.374720\n",
      "Name: correct, dtype: float64\n",
      "condition\n",
      "closer     0.980238\n",
      "further    0.978188\n",
      "Name: correct_class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## what is object-level accuracy broken out condition?\n",
    "print X.groupby('condition')['correct'].apply(lambda x: np.mean(x))\n",
    "\n",
    "## what is class-level accuracy?\n",
    "print X.groupby('condition')['correct_class'].apply(lambda x: np.mean(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition\n",
      "closer     4052.0\n",
      "further    4131.5\n",
      "Name: rt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print X.groupby('condition')['rt'].apply(lambda x: np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.groupby(['gameID','condition'])['correct'].apply(lambda x: np.mean(x))\n",
    "# X.groupby(['gameID'])['correct'].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## plot accuracy by condition and game (individual differences)\n",
    "#X.groupby(['gameID','condition'])['correct'].apply(lambda x: np.mean(x))\n",
    "\n",
    "## subset by full games only\n",
    "all_games = np.unique(X.gameID.values)\n",
    "full_games = [i for i in all_games if np.sum(X['gameID']==i)>50]\n",
    "_X = X[X['gameID'].isin(full_games)]\n",
    "\n",
    "game_acc_close = _X[_X['condition']=='closer'].groupby('gameID')['correct'].apply(lambda x: np.mean(x))\n",
    "game_acc_far = _X[_X['condition']=='further'].groupby('gameID')['correct'].apply(lambda x: np.mean(x))\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.scatter(game_acc_close,game_acc_far)\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.plot([0,1],[0,1],linestyle='dashed')\n",
    "plt.title('accuracy by condition and game')\n",
    "plt.xlabel('close accuracy')\n",
    "plt.ylabel('far accuracy')\n",
    "plt.savefig('./plots/accuracy_by_condition_and_game.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## overall accuracy by category\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "sns.barplot(x='target_category',y='correct',data=X)\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy by category')\n",
    "plt.ylim([0,1])\n",
    "plt.savefig('./plots/accuracy_by_category.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objs = np.unique(X['target'].values)\n",
    "objs = [o for o in objs if o is not None]\n",
    "obj_acc_close = X[X['condition']=='closer'].groupby('target')['correct'].apply(lambda x: np.mean(x))\n",
    "obj_acc_far = X[X['condition']=='further'].groupby('target')['correct'].apply(lambda x: np.mean(x))\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.scatter(obj_acc_close,obj_acc_far)\n",
    "for i, txt in enumerate(objs):\n",
    "    plt.annotate(txt, (obj_acc_close[i],obj_acc_far[i]))\n",
    "plt.xlim([-0.1,1])\n",
    "plt.ylim([-0.1,1]) \n",
    "plt.plot([0,1],[0,1],linestyle='dashed')\n",
    "plt.xlabel('close accuracy')\n",
    "plt.ylabel('far accuracy')\n",
    "plt.title('accuracy by condition and object')\n",
    "plt.savefig('./plots/accuracy_by_condition_and_object.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objs = np.unique(X['target'].values)\n",
    "objs = [o for o in objs if o is not None]\n",
    "obj_acc_close = X[X['condition']=='closer'].groupby('target')['rt'].apply(lambda x: np.mean(x))\n",
    "obj_acc_far = X[X['condition']=='further'].groupby('target')['rt'].apply(lambda x: np.mean(x))\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.scatter(obj_acc_close,obj_acc_far)\n",
    "for i, txt in enumerate(objs):\n",
    "    plt.annotate(txt, (obj_acc_close[i],obj_acc_far[i]))\n",
    "plt.xlim([0,20000])\n",
    "plt.ylim([0,20000])\n",
    "plt.plot([0,20000],[0,20000],linestyle='dashed')\n",
    "plt.xlabel('close RT')\n",
    "plt.ylabel('far RT')\n",
    "plt.title('RT by condition and object')\n",
    "plt.savefig('./plots/RT_by_condition_and_object.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by full games only\n",
    "all_games = np.unique(X.gameID.values)\n",
    "full_games = [i for i in all_games if np.sum(X['gameID']==i)>50]\n",
    "_X = X[X['gameID'].isin(full_games)]\n",
    "\n",
    "game_acc_close = _X[_X['condition']=='closer'].groupby('gameID')['rt'].apply(lambda x: np.median(x))\n",
    "game_acc_far = _X[_X['condition']=='further'].groupby('gameID')['rt'].apply(lambda x: np.median(x))\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.scatter(game_acc_close,game_acc_far)\n",
    "# plt.xlim([0,20000])\n",
    "# plt.ylim([0,20000])\n",
    "# plt.plot([0,20000],[0,20000],linestyle='dashed')\n",
    "plt.title('RT by condition and game')\n",
    "plt.xlabel('close RT')\n",
    "plt.ylabel('far RT')\n",
    "plt.savefig('./plots/RT_by_condition_and_game.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by full games only\n",
    "all_games = np.unique(X.gameID.values)\n",
    "full_games = [i for i in all_games if np.sum(X['gameID']==i)>50]\n",
    "_X = X[X['gameID'].isin(full_games)]\n",
    "\n",
    "acc = _X.groupby('gameID')['correct'].apply(lambda x: np.mean(x))\n",
    "rt = _X.groupby('gameID')['rt'].apply(lambda x: np.mean(x))\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.scatter(acc,rt)\n",
    "plt.xlabel('accuracy')\n",
    "plt.ylabel('RT')\n",
    "plt.title('RT vs. accuracy by game')\n",
    "plt.savefig('./plots/RT_vs_accuracy_by_game.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y = X.groupby(['target','condition'])['correct'].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "\n",
    "## get standardized object list\n",
    "categories = ['bird','car','chair','dog']\n",
    "obj_list = []\n",
    "for cat in categories:\n",
    "    for i,j in h.objcat.iteritems():\n",
    "        if j==cat:\n",
    "            obj_list.append(i)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## initialize confusion matrix\n",
    "confusion = np.zeros((len(obj_list),len(obj_list)))\n",
    "\n",
    "## generate confusion matrix by incrementing in each cell\n",
    "for i,d in X.iterrows():\n",
    "    targ_ind = obj_list.index(d['target'])\n",
    "    choice_ind = obj_list.index(d['choice'])\n",
    "    confusion[targ_ind,choice_ind] += 1\n",
    "    \n",
    "## normalized confusion matrix    \n",
    "normed = np.zeros((len(obj_list),len(obj_list)))\n",
    "for i in np.arange(len(confusion)):\n",
    "    normed[i,:] = confusion[i,:]/np.sum(confusion[i,:])    \n",
    "    \n",
    "## plot confusion matrix\n",
    "from matplotlib import cm\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "cax = ax.matshow(normed,vmin=0,vmax=1,cmap=cm.viridis)\n",
    "plt.xticks(range(len(normed)), obj_list, fontsize=12,rotation='vertical')\n",
    "plt.yticks(range(len(normed)), obj_list, fontsize=12)\n",
    "plt.colorbar(cax,shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/confusion_matrix_all.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### divided by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conds = ['closer','further']\n",
    "\n",
    "for cond in conds:\n",
    "    ## initialize confusion matrix \n",
    "    confusion = np.zeros((len(obj_list),len(obj_list)))\n",
    "\n",
    "    _X = X[X['condition']==cond]\n",
    "    ## generate confusion matrix by incrementing in each cell\n",
    "    for i,d in _X.iterrows():\n",
    "        targ_ind = obj_list.index(d['target'])\n",
    "        choice_ind = obj_list.index(d['choice'])\n",
    "        confusion[targ_ind,choice_ind] += 1\n",
    "\n",
    "    ## normalized confusion matrix    \n",
    "    normed = np.zeros((len(obj_list),len(obj_list)))\n",
    "    for i in np.arange(len(confusion)):\n",
    "        normed[i,:] = confusion[i,:]/np.sum(confusion[i,:])    \n",
    "\n",
    "    ## plot confusion matrix\n",
    "    from matplotlib import cm\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = plt.subplot(111)\n",
    "    cax = ax.matshow(normed,vmin=0,vmax=1,cmap=cm.viridis)\n",
    "    plt.xticks(range(len(normed)), obj_list, fontsize=12,rotation='vertical')\n",
    "    plt.yticks(range(len(normed)), obj_list, fontsize=12)\n",
    "    plt.colorbar(cax,shrink=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./plots/confusion_matrix_{}.pdf'.format(cond))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot difference between close and far conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conds = ['closer','further']\n",
    "normed = np.zeros((len(obj_list),len(obj_list),2))\n",
    "\n",
    "for k,cond in enumerate(conds):\n",
    "    ## initialize confusion matrix \n",
    "    confusion = np.zeros((len(obj_list),len(obj_list)))\n",
    "\n",
    "    _X = X[X['condition']==cond]\n",
    "    ## generate confusion matrix by incrementing in each cell\n",
    "    for i,d in _X.iterrows():\n",
    "        targ_ind = obj_list.index(d['target'])\n",
    "        choice_ind = obj_list.index(d['choice'])\n",
    "        confusion[targ_ind,choice_ind] += 1\n",
    "\n",
    "    ## normalized confusion matrix    \n",
    "    for i in np.arange(len(confusion)):\n",
    "        normed[i,:,k] = confusion[i,:]/np.sum(confusion[i,:])    \n",
    "\n",
    "## plot difference in confusion matrix\n",
    "from matplotlib import cm\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(111)\n",
    "cax = ax.matshow(normed[:,:,0]-normed[:,:,1],vmin=-0.2,vmax=0.2,cmap=cm.BrBG)\n",
    "plt.xticks(range(len(normed)), obj_list, fontsize=12,rotation='vertical')\n",
    "plt.yticks(range(len(normed)), obj_list, fontsize=12)\n",
    "plt.colorbar(cax,shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/confusion_matrix_close_minus_far.pdf')\n",
    "plt.close(fig)\n",
    "\n",
    "# save out to npy \n",
    "np.save('./human_confusion.npy',normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prep jsons for evaluation by passing forward to RSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format for json is a dictionary of dictionaries, where each top-level key refers to one of the renders, e.g. \"trial_20_cuckoo\". For each render, you can look up the similarity with each sketch, referenced with an abbreviated ID taken by trimming the last 12-character string, and appending an underscore, and the trial number. E.g., 'gameID_9903-d6e6a9ff-a878-4bee-b2d5-26e2e239460a_trial_9.npy' ==> '26e2e239460a_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path) as fp:\n",
    "        data = json.load(fp)  \n",
    "    return data\n",
    "\n",
    "## build dictionary to look up the appropriate render ID to use to associate with each sketch\n",
    "data = load_json(json_path)\n",
    "    \n",
    "obj_to_render = dict(zip([i.split('_')[-1] for i in data.keys()], data.keys()))  \n",
    "render_to_obj = dict(zip(data.keys(),[i.split('_')[-1] for i in data.keys()]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simplify_sketch(path): ## example path: 'gameID_9903-d6e6a9ff-a878-4bee-b2d5-26e2e239460a_trial_9.npy' ==> '26e2e239460a_9'\n",
    "    path = '_'.join(os.path.splitext(os.path.basename(path))[0].split('_')[1:])\n",
    "    path = path.split('-')[-1]\n",
    "    path = path.replace('_trial', '')\n",
    "    return path\n",
    "\n",
    "def add_simplified_ids(X):\n",
    "    ## add renderID and sketchID to dataframe\n",
    "    renderID = []\n",
    "    sketchID = []\n",
    "    for i,d in X.iterrows():\n",
    "        renderID.append(obj_to_render[d['target']])\n",
    "        sketchID.append(simplify_sketch(d['fname']))\n",
    "    X['renderID'] = renderID\n",
    "    X['sketchID'] = sketchID    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add simplified id's\n",
    "X = add_simplified_ids(X)\n",
    "\n",
    "## load in normalized confusion matrix\n",
    "confusion = np.load('./human_confusion.npy')\n",
    "close_con = confusion[:,:,0]\n",
    "far_con = confusion[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get confusion matrix lookup table for sketches from each condition\n",
    "\n",
    "## close\n",
    "rows = [i for i in close_con]\n",
    "close_lookup = dict(zip(obj_list, [dict(zip(obj_list,r)) for r in rows])) \n",
    "\n",
    "## far\n",
    "rows = [i for i in far_con]\n",
    "far_lookup = dict(zip(obj_list, [dict(zip(obj_list,r)) for r in rows])) \n",
    "\n",
    "## list of 3d rendered objects\n",
    "render_list = data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 trial_12_bluejay\n",
      "1 trial_7_basset\n",
      "2 trial_2_bullmastiff\n",
      "3 trial_30_doberman\n",
      "4 trial_10_beetle\n",
      "5 trial_11_waiting\n",
      "6 trial_1_bluesport\n",
      "7 trial_31_bluesedan\n",
      "8 trial_4_straight\n",
      "9 trial_8_knob\n",
      "10 trial_15_nightingale\n",
      "11 trial_22_leather\n",
      "12 trial_24_white\n",
      "13 trial_28_chihuahua\n",
      "14 trial_17_redsport\n",
      "15 trial_29_sparrow\n",
      "16 trial_21_woven\n",
      "17 trial_25_goldenretriever\n",
      "18 trial_32_squat\n",
      "19 trial_3_redantique\n",
      "20 trial_9_brown\n",
      "21 trial_27_sling\n",
      "22 trial_16_bloodhound\n",
      "23 trial_23_weimaraner\n",
      "24 trial_26_crow\n",
      "25 trial_13_tomtit\n",
      "26 trial_6_hatchback\n",
      "27 trial_20_cuckoo\n",
      "28 trial_18_pug\n",
      "29 trial_5_inlay\n",
      "30 trial_19_pigeon\n",
      "31 trial_14_robin\n"
     ]
    }
   ],
   "source": [
    "## generate big json dictionary of dictionaries\n",
    "out_json = {}\n",
    "for i,this_render in enumerate(render_list):\n",
    "    print i, this_render\n",
    "    out_json[this_render] = {}\n",
    "    for i,d in X.iterrows():\n",
    "        if d['condition'] == 'closer':\n",
    "            which_dict = close_lookup\n",
    "        elif d['condition'] == 'further':\n",
    "            which_dict = far_lookup\n",
    "        this_sketch = d['sketchID']\n",
    "        this_target = d['target']\n",
    "        similarity = which_dict[this_target][render_to_obj[this_render]]\n",
    "        out_json[this_render][this_sketch] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## output json in the same format as the other similarity jsons\n",
    "output_path = '../models/refModule/json/similarity-human.json'\n",
    "with open(output_path, 'wb') as fp:\n",
    "    json.dump(out_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_path_prefix = '../models/refModule/json/'\n",
    "json_file = 'strict-similarity-pragmatics-fixedpose-augmented-splitbycontext_conv4_2.json'\n",
    "x = load_json(os.path.join(json_path_prefix,json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('../models/bdaInput/sketchData_fixedPose_splitbycontext_augmented2_pilot2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>condition</th>\n",
       "      <th>sketchLabel</th>\n",
       "      <th>Target</th>\n",
       "      <th>Distractor1</th>\n",
       "      <th>Distractor2</th>\n",
       "      <th>Distractor3</th>\n",
       "      <th>coarseGrainedSketchInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>further</td>\n",
       "      <td>d6a8931c94d5_1</td>\n",
       "      <td>trial_8_knob</td>\n",
       "      <td>trial_17_redsport</td>\n",
       "      <td>trial_26_crow</td>\n",
       "      <td>trial_7_basset</td>\n",
       "      <td>further_knob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>further</td>\n",
       "      <td>d6a8931c94d5_2</td>\n",
       "      <td>trial_17_redsport</td>\n",
       "      <td>trial_26_crow</td>\n",
       "      <td>trial_7_basset</td>\n",
       "      <td>trial_8_knob</td>\n",
       "      <td>further_redsport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>closer</td>\n",
       "      <td>d6a8931c94d5_4</td>\n",
       "      <td>trial_28_chihuahua</td>\n",
       "      <td>trial_18_pug</td>\n",
       "      <td>trial_23_weimaraner</td>\n",
       "      <td>trial_30_doberman</td>\n",
       "      <td>closer_chihuahua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>further</td>\n",
       "      <td>d6a8931c94d5_7</td>\n",
       "      <td>trial_3_redantique</td>\n",
       "      <td>trial_14_robin</td>\n",
       "      <td>trial_27_sling</td>\n",
       "      <td>trial_2_bullmastiff</td>\n",
       "      <td>further_redantique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>further</td>\n",
       "      <td>d6a8931c94d5_8</td>\n",
       "      <td>trial_7_basset</td>\n",
       "      <td>trial_17_redsport</td>\n",
       "      <td>trial_26_crow</td>\n",
       "      <td>trial_8_knob</td>\n",
       "      <td>further_basset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 condition     sketchLabel              Target  \\\n",
       "0           0   further  d6a8931c94d5_1        trial_8_knob   \n",
       "1           1   further  d6a8931c94d5_2   trial_17_redsport   \n",
       "2           2    closer  d6a8931c94d5_4  trial_28_chihuahua   \n",
       "3           3   further  d6a8931c94d5_7  trial_3_redantique   \n",
       "4           4   further  d6a8931c94d5_8      trial_7_basset   \n",
       "\n",
       "         Distractor1          Distractor2          Distractor3  \\\n",
       "0  trial_17_redsport        trial_26_crow       trial_7_basset   \n",
       "1      trial_26_crow       trial_7_basset         trial_8_knob   \n",
       "2       trial_18_pug  trial_23_weimaraner    trial_30_doberman   \n",
       "3     trial_14_robin       trial_27_sling  trial_2_bullmastiff   \n",
       "4  trial_17_redsport        trial_26_crow         trial_8_knob   \n",
       "\n",
       "  coarseGrainedSketchInfo  \n",
       "0            further_knob  \n",
       "1        further_redsport  \n",
       "2        closer_chihuahua  \n",
       "3      further_redantique  \n",
       "4          further_basset  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
